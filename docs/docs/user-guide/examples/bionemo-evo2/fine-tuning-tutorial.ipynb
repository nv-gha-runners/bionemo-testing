{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning tutorial for Evo2\n",
    "This tutorial goes through a toy fine-tuning example end to end starting with a fasta and continuing training a hugging\n",
    "face checkpoint on this user defined dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up any prior runs\n",
    "!rm -rf preprocessed_data\n",
    "!rm -rf preatraining_demo\n",
    "!rm -rf nemo2_evo2_1b_8k\n",
    "!rm -rf pretraining_demo\n",
    "!rm -rf training_data_config.yaml\n",
    "!rm -rf preprocess_config.yaml\n",
    "!rm -f chr17.fa.gz\n",
    "!rm -f chr18.fa.gz\n",
    "!rm -f chr21.fa.gz\n",
    "!rm -f chr17.fa\n",
    "!rm -f chr18.fa\n",
    "!rm -f chr21.fa\n",
    "!rm -f chr17_18_21.fa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-02-25 01:11:46--  https://hgdownload.soe.ucsc.edu/goldenpath/hg38/chromosomes/chr17.fa.gz\n",
      "Resolving hgdownload.soe.ucsc.edu (hgdownload.soe.ucsc.edu)... 128.114.119.163\n",
      "Connecting to hgdownload.soe.ucsc.edu (hgdownload.soe.ucsc.edu)|128.114.119.163|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 25930986 (25M) [application/x-gzip]\n",
      "Saving to: ‘chr17.fa.gz.2’\n",
      "\n",
      "chr17.fa.gz.2       100%[===================>]  24.73M  82.3MB/s    in 0.3s    \n",
      "\n",
      "2025-02-25 01:11:49 (82.3 MB/s) - ‘chr17.fa.gz.2’ saved [25930986/25930986]\n",
      "\n",
      "--2025-02-25 01:11:49--  https://hgdownload.soe.ucsc.edu/goldenpath/hg38/chromosomes/chr18.fa.gz\n",
      "Resolving hgdownload.soe.ucsc.edu (hgdownload.soe.ucsc.edu)... 128.114.119.163\n",
      "Connecting to hgdownload.soe.ucsc.edu (hgdownload.soe.ucsc.edu)|128.114.119.163|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 25154367 (24M) [application/x-gzip]\n",
      "Saving to: ‘chr18.fa.gz.1’\n",
      "\n",
      "chr18.fa.gz.1       100%[===================>]  23.99M  54.6MB/s    in 0.4s    \n",
      "\n",
      "2025-02-25 01:11:50 (54.6 MB/s) - ‘chr18.fa.gz.1’ saved [25154367/25154367]\n",
      "\n",
      "--2025-02-25 01:11:50--  https://hgdownload.soe.ucsc.edu/goldenpath/hg38/chromosomes/chr21.fa.gz\n",
      "Resolving hgdownload.soe.ucsc.edu (hgdownload.soe.ucsc.edu)... 128.114.119.163\n",
      "Connecting to hgdownload.soe.ucsc.edu (hgdownload.soe.ucsc.edu)|128.114.119.163|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 12709705 (12M) [application/x-gzip]\n",
      "Saving to: ‘chr21.fa.gz.1’\n",
      "\n",
      "chr21.fa.gz.1       100%[===================>]  12.12M  67.5MB/s    in 0.2s    \n",
      "\n",
      "2025-02-25 01:11:50 (67.5 MB/s) - ‘chr21.fa.gz.1’ saved [12709705/12709705]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "concat_path = \"chr17_18_21.fa\"\n",
    "if not os.path.exists(concat_path):\n",
    "    !wget https://hgdownload.soe.ucsc.edu/goldenpath/hg38/chromosomes/chr17.fa.gz\n",
    "    !wget https://hgdownload.soe.ucsc.edu/goldenpath/hg38/chromosomes/chr18.fa.gz\n",
    "    !wget https://hgdownload.soe.ucsc.edu/goldenpath/hg38/chromosomes/chr21.fa.gz\n",
    "    !zcat chr17.fa.gz > chr17.fa\n",
    "    !zcat chr18.fa.gz > chr18.fa\n",
    "    !zcat chr21.fa.gz > chr21.fa\n",
    "    !cat chr17.fa chr18.fa chr21.fa > chr17_18_21.fa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_fasta_path = os.path.abspath(concat_path)\n",
    "output_dir = os.path.abspath(\"preprocessed_data\")\n",
    "output_yaml = f\"\"\"\n",
    "- datapaths: [\"{full_fasta_path}\"]\n",
    "  output_dir: \"{output_dir}\"\n",
    "  output_prefix: chr17_18_21_uint8_distinct\n",
    "  train_split: 0.9\n",
    "  valid_split: 0.05\n",
    "  test_split: 0.05\n",
    "  overwrite: True\n",
    "  embed_reverse_complement: true\n",
    "  random_reverse_complement: 0.0\n",
    "  random_lineage_dropout: 0.0\n",
    "  include_sequence_id: false\n",
    "  transcribe: \"back_transcribe\"\n",
    "  force_uppercase: false\n",
    "  indexed_dataset_dtype: \"uint8\"\n",
    "  tokenizer_type: \"Byte-Level\"\n",
    "  vocab_file: null\n",
    "  vocab_size: null\n",
    "  merges_file: null\n",
    "  pretrained_tokenizer_model: null\n",
    "  special_tokens: null\n",
    "  fast_hf_tokenizer: true\n",
    "  append_eod: true\n",
    "  enforce_sample_length: null\n",
    "  ftfy: false\n",
    "  workers: 1\n",
    "  preproc_concurrency: 100000\n",
    "  chunksize: 25\n",
    "  drop_empty_sequences: true\n",
    "  nnn_filter: false  # If you split your fasta on NNN (in human these are contigs), then you should set this to true.\n",
    "  seed: 12342  # Not relevant because we are not using random reverse complement or lineage dropout.\n",
    "\"\"\"\n",
    "with open(\"preprocess_config.yaml\", \"w\") as f:\n",
    "    print(output_yaml, file=f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING  | bitsandbytes.cextension]: Could not find the bitsandbytes CUDA binary at PosixPath('/usr/local/lib/python3.12/dist-packages/bitsandbytes/libbitsandbytes_cuda128.so')\n",
      "[WARNING  | bitsandbytes.cextension]: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/selective_scan_interface.py:163: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @custom_fwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/selective_scan_interface.py:239: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @custom_bwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/triton/layer_norm.py:985: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @custom_fwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/triton/layer_norm.py:1044: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @custom_bwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/distributed/tensor_parallel.py:25: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @custom_fwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/distributed/tensor_parallel.py:61: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @custom_bwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/triton/ssd_combined.py:757: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @custom_fwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/triton/ssd_combined.py:835: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @custom_bwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n",
      "\n",
      "[NeMo I 2025-02-25 01:12:03 nemo_logging:393] Using byte-level tokenization\n",
      "[NeMo I 2025-02-25 01:12:03 nemo_logging:393] Created temporary binary datasets: /workspaces/bionemo-framework/docs/docs/user-guide/examples/bionemo-evo2/preprocessed_data/chr17_18_21_uint8_distinct_byte-level_train.bin.tmp /workspaces/bionemo-framework/docs/docs/user-guide/examples/bionemo-evo2/preprocessed_data/chr17_18_21_uint8_distinct_byte-level_val.bin.tmp /workspaces/bionemo-framework/docs/docs/user-guide/examples/bionemo-evo2/preprocessed_data/chr17_18_21_uint8_distinct_byte-level_test.bin.tmp\n",
      "[NeMo I 2025-02-25 01:12:32 nemo_logging:393] Average preprocessing time per sequence: 1.337763786315918\n",
      "[NeMo I 2025-02-25 01:12:32 nemo_logging:393] Average indexing time per sequence: 3.9368359645207724\n",
      "[NeMo I 2025-02-25 01:12:32 nemo_logging:393] Number of sequences processed: 6\n",
      "[NeMo I 2025-02-25 01:12:32 nemo_logging:393] Finished preprocessing chr17_18_21_uint8_distinct ([PosixPath('/workspaces/bionemo-framework/docs/docs/user-guide/examples/bionemo-evo2/chr17_18_21.fa')]) in 28.605 seconds with 1 workers.\n"
     ]
    }
   ],
   "source": [
    "!preprocess_evo2 --config preprocess_config.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 402M\n",
      "-rw-r--r-- 1 ubuntu ubuntu 159M Feb 25 01:12 chr17_18_21_uint8_distinct_byte-level_test.bin\n",
      "-rw-r--r-- 1 ubuntu ubuntu   82 Feb 25 01:12 chr17_18_21_uint8_distinct_byte-level_test.idx\n",
      "-rw-r--r-- 1 ubuntu ubuntu 154M Feb 25 01:12 chr17_18_21_uint8_distinct_byte-level_train.bin\n",
      "-rw-r--r-- 1 ubuntu ubuntu   82 Feb 25 01:12 chr17_18_21_uint8_distinct_byte-level_train.idx\n",
      "-rw-r--r-- 1 ubuntu ubuntu  90M Feb 25 01:12 chr17_18_21_uint8_distinct_byte-level_val.bin\n",
      "-rw-r--r-- 1 ubuntu ubuntu   82 Feb 25 01:12 chr17_18_21_uint8_distinct_byte-level_val.idx\n"
     ]
    }
   ],
   "source": [
    "!ls -lh preprocessed_data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING  | bitsandbytes.cextension]: Could not find the bitsandbytes CUDA binary at PosixPath('/usr/local/lib/python3.12/dist-packages/bitsandbytes/libbitsandbytes_cuda128.so')\n",
      "[WARNING  | bitsandbytes.cextension]: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "[NeMo W 2025-02-25 01:12:44 nemo_logging:405] /usr/local/lib/python3.12/dist-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "      warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n",
      "    \n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/selective_scan_interface.py:163: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @custom_fwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/selective_scan_interface.py:239: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @custom_bwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/triton/layer_norm.py:985: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @custom_fwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/triton/layer_norm.py:1044: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @custom_bwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/distributed/tensor_parallel.py:25: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @custom_fwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/distributed/tensor_parallel.py:61: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @custom_bwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/triton/ssd_combined.py:757: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @custom_fwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/triton/ssd_combined.py:835: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @custom_bwd\n",
      "\n",
      "[NeMo I 2025-02-25 01:12:48 nemo_logging:393] Using byte-level tokenization\n",
      "[INFO     | pytorch_lightning.utilities.rank_zero]: GPU available: True (cuda), used: False\n",
      "[INFO     | pytorch_lightning.utilities.rank_zero]: TPU available: False, using: 0 TPU cores\n",
      "[INFO     | pytorch_lightning.utilities.rank_zero]: HPU available: False, using: 0 HPUs\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/setup.py:177: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "\n",
      "[NeMo I 2025-02-25 01:12:48 nemo_logging:393] Fixing mis-match between ddp-config & mcore-optimizer config\n",
      "[NeMo I 2025-02-25 01:12:48 nemo_logging:393] Rank 0 has data parallel group : [0]\n",
      "[NeMo I 2025-02-25 01:12:48 nemo_logging:393] Rank 0 has combined group of data parallel and context parallel : [0]\n",
      "[NeMo I 2025-02-25 01:12:48 nemo_logging:393] All data parallel group ranks with context parallel combined: [[0]]\n",
      "[NeMo I 2025-02-25 01:12:48 nemo_logging:393] Ranks 0 has data parallel rank: 0\n",
      "[NeMo I 2025-02-25 01:12:48 nemo_logging:393] Rank 0 has context parallel group: [0]\n",
      "[NeMo I 2025-02-25 01:12:48 nemo_logging:393] All context parallel group ranks: [[0]]\n",
      "[NeMo I 2025-02-25 01:12:48 nemo_logging:393] Ranks 0 has context parallel rank: 0\n",
      "[NeMo I 2025-02-25 01:12:48 nemo_logging:393] Rank 0 has model parallel group: [0]\n",
      "[NeMo I 2025-02-25 01:12:48 nemo_logging:393] All model parallel group ranks: [[0]]\n",
      "[NeMo I 2025-02-25 01:12:48 nemo_logging:393] Rank 0 has tensor model parallel group: [0]\n",
      "[NeMo I 2025-02-25 01:12:48 nemo_logging:393] All tensor model parallel group ranks: [[0]]\n",
      "[NeMo I 2025-02-25 01:12:48 nemo_logging:393] Rank 0 has tensor model parallel rank: 0\n",
      "[NeMo I 2025-02-25 01:12:48 nemo_logging:393] Rank 0 has pipeline model parallel group: [0]\n",
      "[NeMo I 2025-02-25 01:12:48 nemo_logging:393] Rank 0 has embedding group: [0]\n",
      "[NeMo I 2025-02-25 01:12:48 nemo_logging:393] All pipeline model parallel group ranks: [[0]]\n",
      "[NeMo I 2025-02-25 01:12:48 nemo_logging:393] Rank 0 has pipeline model parallel rank 0\n",
      "[NeMo I 2025-02-25 01:12:48 nemo_logging:393] All embedding group ranks: [[0]]\n",
      "[NeMo I 2025-02-25 01:12:48 nemo_logging:393] Rank 0 has embedding rank: 0\n",
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1\n",
      "[INFO     | pytorch_lightning.utilities.rank_zero]: ----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=gloo\n",
      "All distributed processes registered. Starting with 1 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/trainer.py:1090: `trainer.init_module` cannot fully support proper instantiation of your model with the `MegatronStrategy` strategy. Please instantiate your model inside the`LightningModule.configure_model` hook instead\n",
      "\n",
      "[NeMo I 2025-02-25 01:12:48 nemo_logging:393] Padded vocab_size: 512, original vocab_size: 512, dummy tokens: 0.\n",
      "[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context\n",
      "[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context\n",
      "[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context\n",
      "[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context\n",
      "[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context\n",
      "[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context\n",
      "[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context\n",
      "[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context\n",
      "[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context\n",
      "[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context\n",
      "[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context\n",
      "[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context\n",
      "[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context\n",
      "[WARNING  | megatron.core.tensor_parallel.random]: CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-02-25 01:12:49 nemo_logging:405] Could not copy Trainer's 'max_steps' to LR scheduler's 'max_steps'. If you are not using an LR scheduler, this warning can safely be ignored.\n",
      "[WARNING  | bitsandbytes.cextension]: Could not find the bitsandbytes CUDA binary at PosixPath('/usr/local/lib/python3.12/dist-packages/bitsandbytes/libbitsandbytes_cuda128.so')\n",
      "[WARNING  | bitsandbytes.cextension]: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "[NeMo W 2025-02-25 01:12:59 nemo_logging:405] /usr/local/lib/python3.12/dist-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "      warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n",
      "    \n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/selective_scan_interface.py:163: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @custom_fwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/selective_scan_interface.py:239: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @custom_bwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/triton/layer_norm.py:985: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @custom_fwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/triton/layer_norm.py:1044: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @custom_bwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/distributed/tensor_parallel.py:25: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @custom_fwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/distributed/tensor_parallel.py:61: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @custom_bwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/triton/ssd_combined.py:757: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @custom_fwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/triton/ssd_combined.py:835: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @custom_bwd\n",
      "\n",
      "[NeMo I 2025-02-25 01:13:03 nemo_logging:393] Converted Hyena model to Nemo, model saved to nemo2_evo2_1b_8k\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/torch/__init__.py:1074: FutureWarning: `torch.distributed.reduce_op` is deprecated, please use `torch.distributed.ReduceOp` instead\n",
      "  return isinstance(obj, torch.Tensor)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!evo2_convert_to_nemo2 \\\n",
    "  --model-path hf://arcinstitute/savanna_evo2_1b_base \\\n",
    "  --model-size 1b --output-dir nemo2_evo2_1b_8k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "output_pfx = str(Path(os.path.abspath(\"preprocessed_data\"))/\"chr17_18_21_uint8_distinct_byte-level\")\n",
    "output_yaml = f\"\"\"\n",
    "- dataset_prefix: {output_pfx}_train\n",
    "  dataset_split: train\n",
    "  dataset_weight: 1.0\n",
    "- dataset_prefix: {output_pfx}_val\n",
    "  dataset_split: validation\n",
    "  dataset_weight: 1.0\n",
    "- dataset_prefix: {output_pfx}_test\n",
    "  dataset_split: test\n",
    "  dataset_weight: 1.0\n",
    "\"\"\"\n",
    "with open(\"training_data_config.yaml\", \"w\") as f:\n",
    "    print(output_yaml, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARNING  | bitsandbytes.cextension]: Could not find the bitsandbytes CUDA binary at PosixPath('/usr/local/lib/python3.12/dist-packages/bitsandbytes/libbitsandbytes_cuda128.so')\n",
      "[WARNING  | bitsandbytes.cextension]: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "[NeMo W 2025-02-25 01:13:17 nemo_logging:405] /usr/local/lib/python3.12/dist-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "      warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n",
      "    \n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/selective_scan_interface.py:163: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @custom_fwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/selective_scan_interface.py:239: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @custom_bwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/triton/layer_norm.py:985: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @custom_fwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/triton/layer_norm.py:1044: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @custom_bwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/distributed/tensor_parallel.py:25: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @custom_fwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/distributed/tensor_parallel.py:61: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @custom_bwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/triton/ssd_combined.py:757: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @custom_fwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/triton/ssd_combined.py:835: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @custom_bwd\n",
      "\n",
      "[NeMo I 2025-02-25 01:13:19 nemo_logging:393] Using byte-level tokenization\n",
      "[WARNING  | py.warnings        ]: /workspaces/bionemo-framework/3rdparty/NeMo/nemo/collections/llm/gpt/data/pre_training.py:190: UserWarning: split='900,50,50' will be ignored since datasets are being created from 3 separate distributions.\n",
      "  warnings.warn(\n",
      "\n",
      "[INFO     | pytorch_lightning.utilities.rank_zero]: Trainer already configured with model summary callbacks: [<class 'lightning.pytorch.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "[INFO     | pytorch_lightning.utilities.rank_zero]: GPU available: True (cuda), used: True\n",
      "[INFO     | pytorch_lightning.utilities.rank_zero]: TPU available: False, using: 0 TPU cores\n",
      "[INFO     | pytorch_lightning.utilities.rank_zero]: HPU available: False, using: 0 HPUs\n",
      "[NeMo W 2025-02-25 01:13:19 nemo_logging:405] No version folders would be created under the log folder as 'resume_if_exists' is enabled.\n",
      "[NeMo I 2025-02-25 01:13:19 nemo_logging:393] Experiments will be logged at pretraining_demo/default\n",
      "[NeMo W 2025-02-25 01:13:19 nemo_logging:405] \"update_logger_directory\" is True. Overwriting tensorboard logger \"save_dir\" to pretraining_demo/dummy\n",
      "[NeMo W 2025-02-25 01:13:19 nemo_logging:405] There were no checkpoints found in checkpoint_dir or no checkpoint folder at checkpoint_dir :pretraining_demo. Training from scratch.\n",
      "[NeMo I 2025-02-25 01:13:19 nemo_logging:393] Fixing mis-match between ddp-config & mcore-optimizer config\n",
      "[NeMo I 2025-02-25 01:13:19 nemo_logging:393] Rank 0 has data parallel group : [0]\n",
      "[NeMo I 2025-02-25 01:13:19 nemo_logging:393] Rank 0 has combined group of data parallel and context parallel : [0]\n",
      "[NeMo I 2025-02-25 01:13:19 nemo_logging:393] All data parallel group ranks with context parallel combined: [[0]]\n",
      "[NeMo I 2025-02-25 01:13:19 nemo_logging:393] Ranks 0 has data parallel rank: 0\n",
      "[NeMo I 2025-02-25 01:13:19 nemo_logging:393] Rank 0 has context parallel group: [0]\n",
      "[NeMo I 2025-02-25 01:13:19 nemo_logging:393] All context parallel group ranks: [[0]]\n",
      "[NeMo I 2025-02-25 01:13:19 nemo_logging:393] Ranks 0 has context parallel rank: 0\n",
      "[NeMo I 2025-02-25 01:13:19 nemo_logging:393] Rank 0 has model parallel group: [0]\n",
      "[NeMo I 2025-02-25 01:13:19 nemo_logging:393] All model parallel group ranks: [[0]]\n",
      "[NeMo I 2025-02-25 01:13:19 nemo_logging:393] Rank 0 has tensor model parallel group: [0]\n",
      "[NeMo I 2025-02-25 01:13:19 nemo_logging:393] All tensor model parallel group ranks: [[0]]\n",
      "[NeMo I 2025-02-25 01:13:19 nemo_logging:393] Rank 0 has tensor model parallel rank: 0\n",
      "[NeMo I 2025-02-25 01:13:19 nemo_logging:393] Rank 0 has pipeline model parallel group: [0]\n",
      "[NeMo I 2025-02-25 01:13:19 nemo_logging:393] Rank 0 has embedding group: [0]\n",
      "[NeMo I 2025-02-25 01:13:19 nemo_logging:393] All pipeline model parallel group ranks: [[0]]\n",
      "[NeMo I 2025-02-25 01:13:19 nemo_logging:393] Rank 0 has pipeline model parallel rank 0\n",
      "[NeMo I 2025-02-25 01:13:19 nemo_logging:393] All embedding group ranks: [[0]]\n",
      "[NeMo I 2025-02-25 01:13:19 nemo_logging:393] Rank 0 has embedding rank: 0\n",
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1\n",
      "[INFO     | pytorch_lightning.utilities.rank_zero]: ----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 1 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[NeMo I 2025-02-25 01:13:20 utils:302] Building Evo2Dataset splits with sizes=[200, 120, 2] and config=GPTDatasetConfig(random_seed=1234, sequence_length=1024, blend=None, blend_per_split=[(['/workspaces/bionemo-framework/docs/docs/user-guide/examples/bionemo-evo2/preprocessed_data/chr17_18_21_uint8_distinct_byte-level_train'], [1.0]), (['/workspaces/bionemo-framework/docs/docs/user-guide/examples/bionemo-evo2/preprocessed_data/chr17_18_21_uint8_distinct_byte-level_val'], [1.0]), (['/workspaces/bionemo-framework/docs/docs/user-guide/examples/bionemo-evo2/preprocessed_data/chr17_18_21_uint8_distinct_byte-level_test'], [1.0])], split=None, split_matrix=None, num_dataset_builder_threads=1, path_to_cache=None, mmap_bin_files=True, mock=False, tokenizer=<nemo.collections.common.tokenizers.bytelevel_tokenizers.ByteLevelTokenizer object at 0x7e5db038ffe0>, reset_position_ids=False, reset_attention_mask=False, eod_mask_loss=False, create_attention_mask=False, drop_last_partial_validation_sequence=True, add_extra_token_to_sequence=True, s3_cache_path=None)\n",
      "[NeMo I 2025-02-25 01:13:20 utils:302] Load the _IndexReader from /workspaces/bionemo-framework/docs/docs/user-guide/examples/bionemo-evo2/preprocessed_data/chr17_18_21_uint8_distinct_byte-level_train.idx\n",
      "[NeMo I 2025-02-25 01:13:20 utils:302] \tExtract the sequence lengths\n",
      "[NeMo I 2025-02-25 01:13:20 utils:302] \tExtract the sequence pointers\n",
      "[NeMo I 2025-02-25 01:13:20 utils:302] \tExtract the document indices\n",
      "[NeMo I 2025-02-25 01:13:20 utils:302] > total number of sequences: 2\n",
      "[NeMo I 2025-02-25 01:13:20 utils:302] > total number of documents: 2\n",
      "[NeMo I 2025-02-25 01:13:20 utils:302] Build and save the Evo2Dataset train indices\n",
      "[NeMo I 2025-02-25 01:13:20 utils:302] > total number of samples: 156979\n",
      "[NeMo I 2025-02-25 01:13:20 utils:302] > total number of epochs: 1\n",
      "[NeMo I 2025-02-25 01:13:20 utils:302] Load the _IndexReader from /workspaces/bionemo-framework/docs/docs/user-guide/examples/bionemo-evo2/preprocessed_data/chr17_18_21_uint8_distinct_byte-level_val.idx\n",
      "[NeMo I 2025-02-25 01:13:20 utils:302] \tExtract the sequence lengths\n",
      "[NeMo I 2025-02-25 01:13:20 utils:302] \tExtract the sequence pointers\n",
      "[NeMo I 2025-02-25 01:13:20 utils:302] \tExtract the document indices\n",
      "[NeMo I 2025-02-25 01:13:20 utils:302] > total number of sequences: 2\n",
      "[NeMo I 2025-02-25 01:13:20 utils:302] > total number of documents: 2\n",
      "[NeMo I 2025-02-25 01:13:20 utils:302] Build and save the Evo2Dataset valid indices\n",
      "[NeMo I 2025-02-25 01:13:20 utils:302] > total number of samples: 91230\n",
      "[NeMo I 2025-02-25 01:13:20 utils:302] > total number of epochs: 1\n",
      "[NeMo I 2025-02-25 01:13:20 utils:302] Load the _IndexReader from /workspaces/bionemo-framework/docs/docs/user-guide/examples/bionemo-evo2/preprocessed_data/chr17_18_21_uint8_distinct_byte-level_test.idx\n",
      "[NeMo I 2025-02-25 01:13:20 utils:302] \tExtract the sequence lengths\n",
      "[NeMo I 2025-02-25 01:13:20 utils:302] \tExtract the sequence pointers\n",
      "[NeMo I 2025-02-25 01:13:20 utils:302] \tExtract the document indices\n",
      "[NeMo I 2025-02-25 01:13:20 utils:302] > total number of sequences: 2\n",
      "[NeMo I 2025-02-25 01:13:20 utils:302] > total number of documents: 2\n",
      "[NeMo I 2025-02-25 01:13:20 utils:302] Build and save the Evo2Dataset test indices\n",
      "[NeMo I 2025-02-25 01:13:20 utils:302] > total number of samples: 162612\n",
      "[NeMo I 2025-02-25 01:13:20 utils:302] > total number of epochs: 1\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory /workspaces/bionemo-framework/docs/docs/user-guide/examples/bionemo-evo2/pretraining_demo exists and is not empty.\n",
      "\n",
      "[NeMo I 2025-02-25 01:13:20 nemo_logging:393] Padded vocab_size: 512, original vocab_size: 512, dummy tokens: 0.\n",
      "[NeMo W 2025-02-25 01:13:20 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-02-25 01:13:20 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-02-25 01:13:20 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-02-25 01:13:20 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-02-25 01:13:20 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-02-25 01:13:20 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-02-25 01:13:20 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-02-25 01:13:20 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-02-25 01:13:20 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-02-25 01:13:20 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-02-25 01:13:20 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-02-25 01:13:20 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-02-25 01:13:20 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-02-25 01:13:20 random:220] CPU RNG state changed within GPU RNG context\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "[NeMo I 2025-02-25 01:13:20 nemo_logging:393] Copying Trainer's 'max_steps' (100) to LR scheduler's 'max_steps'.\n",
      "[NeMo I 2025-02-25 01:13:20 num_microbatches_calculator:228] setting number of microbatches to constant 1\n",
      "[NeMo I 2025-02-25 01:13:20 nemo_logging:393]  > number of parameters on (tensor, pipeline) model parallel rank (0, 0): 1108204800\n",
      "[NeMo I 2025-02-25 01:13:20 utils:302] Setting up DistributedDataParallel with config DistributedDataParallelConfig(grad_reduce_in_fp32=False, overlap_grad_reduce=False, overlap_param_gather=False, align_param_gather=False, use_distributed_optimizer=True, num_distributed_optimizer_instances=1, check_for_nan_in_grad=True, check_for_large_grads=False, bucket_size=None, average_in_collective=True, fp8_param_gather=False)\n",
      "[NeMo I 2025-02-25 01:13:20 utils:323] Number of buckets for gradient all-reduce / reduce-scatter: 1\n",
      "    Params for bucket 1 (1108204800 elements):\n",
      "    \tmodule.decoder.layers.23.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.15.mixer.mixer.filter.h\n",
      "    \tmodule.decoder.layers.13.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.10.self_attention.linear_proj.bias\n",
      "    \tmodule.decoder.layers.7.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.1.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.23.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.21.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.19.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.16.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.13.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.11.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.8.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.6.mixer.mixer.filter.p\n",
      "    \tmodule.decoder.layers.4.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.17.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.16.mixer.mixer.filter.gamma\n",
      "    \tmodule.decoder.layers.12.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.2.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.23.mixer.mixer.filter.p\n",
      "    \tmodule.decoder.layers.21.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.19.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.13.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.10.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.8.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.6.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.3.self_attention.linear_qkv.weight\n",
      "    \tmodule.decoder.layers.2.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.1.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.19.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.17.self_attention.linear_qkv.layer_norm_weight\n",
      "    \tmodule.decoder.layers.14.mixer.mixer.short_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.11.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.6.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.5.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.2.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.24.self_attention.linear_proj.bias\n",
      "    \tmodule.decoder.layers.23.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.20.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.18.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.16.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.15.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.12.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.10.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.8.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.5.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.17.self_attention.linear_proj.weight\n",
      "    \tmodule.decoder.layers.23.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.22.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.8.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.7.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.0.mixer.mixer.short_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.22.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.14.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.12.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.9.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.7.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.5.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.0.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.19.mixer.mixer.filter.h\n",
      "    \tmodule.decoder.layers.16.mixer.mixer.filter.R\n",
      "    \tmodule.decoder.layers.15.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.10.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.6.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.4.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.2.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.24.self_attention.linear_qkv.weight\n",
      "    \tmodule.decoder.layers.22.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.20.mixer.mixer.filter.gamma\n",
      "    \tmodule.decoder.layers.14.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.12.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.4.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.0.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.23.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.21.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.16.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.12.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.10.self_attention.linear_qkv.layer_norm_weight\n",
      "    \tmodule.decoder.layers.8.mixer.mixer.filter.h\n",
      "    \tmodule.decoder.layers.6.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.3.self_attention.linear_proj.weight\n",
      "    \tmodule.decoder.layers.1.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.21.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.16.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.13.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.11.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.9.mixer.mixer.filter.gamma\n",
      "    \tmodule.decoder.layers.6.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.4.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.23.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.20.mixer.mixer.filter.R\n",
      "    \tmodule.decoder.layers.18.mixer.mixer.short_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.15.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.10.self_attention.linear_proj.weight\n",
      "    \tmodule.decoder.layers.5.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.2.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.0.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.23.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.21.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.19.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.16.mixer.mixer.filter.p\n",
      "    \tmodule.decoder.layers.15.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.6.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.3.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.3.self_attention.linear_proj.bias\n",
      "    \tmodule.decoder.layers.22.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.20.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.12.mixer.mixer.filter.h\n",
      "    \tmodule.decoder.layers.9.mixer.mixer.filter.R\n",
      "    \tmodule.decoder.layers.7.mixer.mixer.short_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.4.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.0.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.23.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.20.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.18.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.15.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.13.mixer.mixer.filter.gamma\n",
      "    \tmodule.decoder.layers.8.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.5.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.3.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.2.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.21.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.16.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.14.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.9.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.22.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.20.mixer.mixer.filter.p\n",
      "    \tmodule.decoder.layers.18.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.14.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.9.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.7.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.5.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.4.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.1.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.16.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.13.mixer.mixer.filter.R\n",
      "    \tmodule.decoder.layers.11.mixer.mixer.short_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.3.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.17.self_attention.linear_qkv.weight\n",
      "    \tmodule.decoder.layers.24.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.22.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.20.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.14.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.12.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.9.mixer.mixer.filter.p\n",
      "    \tmodule.decoder.layers.7.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.5.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.2.mixer.mixer.filter.R\n",
      "    \tmodule.decoder.layers.20.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.19.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.16.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.15.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.13.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.5.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.3.self_attention.linear_qkv.layer_norm_weight\n",
      "    \tmodule.decoder.layers.1.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.18.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.24.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.22.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.19.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.13.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.11.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.9.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.6.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.4.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.22.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.21.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.14.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.9.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.8.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.2.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.0.mlp.linear_fc2.weight\n",
      "    \tmodule.embedding.word_embeddings.weight\n",
      "    \tmodule.decoder.layers.23.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.21.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.19.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.16.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.13.mixer.mixer.filter.p\n",
      "    \tmodule.decoder.layers.11.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.8.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.1.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.1.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.1.mixer.mixer.filter.h\n",
      "    \tmodule.decoder.final_norm.weight\n",
      "    \tmodule.decoder.layers.24.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.20.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.18.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.5.mixer.mixer.filter.h\n",
      "    \tmodule.decoder.layers.2.mixer.mixer.filter.p\n",
      "    \tmodule.decoder.layers.18.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.16.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.15.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.13.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.10.self_attention.linear_qkv.weight\n",
      "    \tmodule.decoder.layers.8.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.6.mixer.mixer.filter.gamma\n",
      "    \tmodule.decoder.layers.1.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.24.self_attention.linear_qkv.layer_norm_weight\n",
      "    \tmodule.decoder.layers.22.mixer.mixer.filter.h\n",
      "    \tmodule.decoder.layers.20.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.13.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.12.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.9.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.7.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.23.mixer.mixer.filter.gamma\n",
      "    \tmodule.decoder.layers.20.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.18.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.15.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.12.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.11.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.7.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.2.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.0.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.0.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.24.self_attention.linear_proj.weight\n",
      "    \tmodule.decoder.layers.19.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.15.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.14.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.9.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.6.mixer.mixer.filter.R\n",
      "    \tmodule.decoder.layers.4.mixer.mixer.short_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.1.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.17.self_attention.linear_proj.bias\n",
      "    \tmodule.decoder.layers.17.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.20.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.14.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.12.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.9.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.7.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.5.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.0.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.23.mixer.mixer.filter.R\n",
      "    \tmodule.decoder.layers.21.mixer.mixer.short_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.18.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.13.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.11.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.8.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.6.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.2.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.22.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.19.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.17.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.11.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.9.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.6.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.4.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.2.mixer.mixer.filter.gamma\n",
      "[NeMo I 2025-02-25 01:13:20 utils:302] Setting up optimizer with config OptimizerConfig(optimizer='adam', lr=0.0001, min_lr=None, decoupled_lr=None, decoupled_min_lr=None, weight_decay=0.01, fp16=False, bf16=True, params_dtype=torch.bfloat16, use_precision_aware_optimizer=False, main_grads_dtype=torch.float32, main_params_dtype=torch.float32, exp_avg_dtype=torch.float32, exp_avg_sq_dtype=torch.float32, loss_scale=None, initial_loss_scale=4294967296, min_loss_scale=1.0, loss_scale_window=1000, hysteresis=2, adam_beta1=0.9, adam_beta2=0.95, adam_eps=1e-08, sgd_momentum=0.9, use_distributed_optimizer=True, overlap_param_gather_with_optimizer_step=False, optimizer_cpu_offload=False, optimizer_offload_fraction=0.0, use_torch_optimizer_for_cpu_offload=False, overlap_cpu_optimizer_d2h_h2d=False, pin_cpu_grads=True, pin_cpu_params=True, clip_grad=1.0, log_num_zeros_in_grad=False, barrier_with_L1_time=False, timers=None, config_logger_dir='')\n",
      "[NeMo I 2025-02-25 01:13:20 nemo_logging:393] Doing selective restore from RestoreConfig(path='nemo2_evo2_1b_8k', adapter_path=None, load_model_state=True, load_optim_state=False, load_artifacts=True)\n",
      "[WARNING  | py.warnings        ]: /workspaces/bionemo-framework/3rdparty/Megatron-LM/megatron/core/dist_checkpointing/strategies/torch.py:847: FutureWarning: `load_state_dict` is deprecated and will be removed in future versions. Please use `load` instead.\n",
      "  checkpoint.load_state_dict(\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/torch/distributed/checkpoint/planner_helpers.py:316: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.\n",
      "  device = getattr(value, \"device\", None)\n",
      "\n",
      "[NeMo I 2025-02-25 01:13:21 nemo_logging:393] Restoring model weights from RestoreConfig(path='nemo2_evo2_1b_8k', adapter_path=None, load_model_state=True, load_optim_state=False, load_artifacts=True)\n",
      "[NeMo I 2025-02-25 01:13:21 nemo_logging:393] Finished restoring from RestoreConfig(path='nemo2_evo2_1b_8k', adapter_path=None, load_model_state=True, load_optim_state=False, load_artifacts=True), cleaning up.\n",
      "┏━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
      "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName                               \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType             \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
      "┡━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
      "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ module                              │ DDP               │  1.1 B │ train │\n",
      "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ module.module                       │ Float16Module     │  1.1 B │ train │\n",
      "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ module.module.module                │ HyenaModel        │  1.1 B │ train │\n",
      "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ module.module.module.embedding      │ LanguageModelEmb… │  983 K │ train │\n",
      "│\u001b[2m \u001b[0m\u001b[2m4\u001b[0m\u001b[2m \u001b[0m│ module.module.module.rotary_pos_emb │ RotaryEmbedding   │      0 │ train │\n",
      "│\u001b[2m \u001b[0m\u001b[2m5\u001b[0m\u001b[2m \u001b[0m│ module.module.module.decoder        │ HyenaStack        │  1.1 B │ train │\n",
      "│\u001b[2m \u001b[0m\u001b[2m6\u001b[0m\u001b[2m \u001b[0m│ module.module.module.output_layer   │ ColumnParallelLi… │      0 │ train │\n",
      "└───┴─────────────────────────────────────┴───────────────────┴────────┴───────┘\n",
      "\u001b[1mTrainable params\u001b[0m: 1.1 B                                                         \n",
      "\u001b[1mNon-trainable params\u001b[0m: 0                                                         \n",
      "\u001b[1mTotal params\u001b[0m: 1.1 B                                                             \n",
      "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 4.4 K                                   \n",
      "\u001b[1mModules in train mode\u001b[0m: 356                                                      \n",
      "\u001b[1mModules in eval mode\u001b[0m: 0                                                         \n",
      "[NeMo W 2025-02-25 01:13:30 rerun_state_machine:1264] Implicit initialization of Rerun State Machine!\n",
      "[NeMo W 2025-02-25 01:13:30 rerun_state_machine:239] RerunStateMachine initialized in mode RerunMode.DISABLED\n",
      "Training epoch 0, iteration 0/99 | lr: 0 | global_batch_size: 2 | global_step: 0 | reduced_train_loss: 1.246 | train_step_timing in s: 9.091\n",
      "Training epoch 0, iteration 1/99 | lr: 2e-05 | global_batch_size: 2 | global_step: 1 | reduced_train_loss: 1.322 | train_step_timing in s: 1.682 | consumed_samples: 4\n",
      "Training epoch 0, iteration 2/99 | lr: 4e-05 | global_batch_size: 2 | global_step: 2 | reduced_train_loss: 1.217 | train_step_timing in s: 0.4297 | consumed_samples: 6\n",
      "Training epoch 0, iteration 3/99 | lr: 6e-05 | global_batch_size: 2 | global_step: 3 | reduced_train_loss: 1.277 | train_step_timing in s: 0.4295 | consumed_samples: 8\n",
      "Training epoch 0, iteration 4/99 | lr: 8e-05 | global_batch_size: 2 | global_step: 4 | reduced_train_loss: 1.3 | train_step_timing in s: 0.4304 | consumed_samples: 10\n",
      "Training epoch 0, iteration 5/99 | lr: 0.0001 | global_batch_size: 2 | global_step: 5 | reduced_train_loss: 1.309 | train_step_timing in s: 0.4296 | consumed_samples: 12\n",
      "Training epoch 0, iteration 6/99 | lr: 3e-05 | global_batch_size: 2 | global_step: 6 | reduced_train_loss: 1.062 | train_step_timing in s: 0.4301 | consumed_samples: 14\n",
      "Training epoch 0, iteration 7/99 | lr: 3e-05 | global_batch_size: 2 | global_step: 7 | reduced_train_loss: 1.287 | train_step_timing in s: 0.4293 | consumed_samples: 16\n",
      "Training epoch 0, iteration 8/99 | lr: 3e-05 | global_batch_size: 2 | global_step: 8 | reduced_train_loss: 1.292 | train_step_timing in s: 0.4287 | consumed_samples: 18\n",
      "Training epoch 0, iteration 9/99 | lr: 3e-05 | global_batch_size: 2 | global_step: 9 | reduced_train_loss: 1.274 | train_step_timing in s: 0.4288 | consumed_samples: 20\n",
      "Training epoch 0, iteration 10/99 | lr: 3e-05 | global_batch_size: 2 | global_step: 10 | reduced_train_loss: 1.131 | train_step_timing in s: 0.4289 | consumed_samples: 22\n",
      "Training epoch 0, iteration 11/99 | lr: 3e-05 | global_batch_size: 2 | global_step: 11 | reduced_train_loss: 1.243 | train_step_timing in s: 0.4298 | consumed_samples: 24\n",
      "Training epoch 0, iteration 12/99 | lr: 3e-05 | global_batch_size: 2 | global_step: 12 | reduced_train_loss: 1.226 | train_step_timing in s: 0.4305 | consumed_samples: 26\n",
      "Training epoch 0, iteration 13/99 | lr: 3e-05 | global_batch_size: 2 | global_step: 13 | reduced_train_loss: 1.316 | train_step_timing in s: 0.429 | consumed_samples: 28\n",
      "Training epoch 0, iteration 14/99 | lr: 3e-05 | global_batch_size: 2 | global_step: 14 | reduced_train_loss: 1.263 | train_step_timing in s: 0.4286 | consumed_samples: 30\n",
      "Training epoch 0, iteration 15/99 | lr: 3e-05 | global_batch_size: 2 | global_step: 15 | reduced_train_loss: 1.305 | train_step_timing in s: 0.43 | consumed_samples: 32\n",
      "Training epoch 0, iteration 16/99 | lr: 3e-05 | global_batch_size: 2 | global_step: 16 | reduced_train_loss: 1.286 | train_step_timing in s: 0.4297 | consumed_samples: 34\n",
      "Training epoch 0, iteration 17/99 | lr: 3e-05 | global_batch_size: 2 | global_step: 17 | reduced_train_loss: 1.272 | train_step_timing in s: 0.4298 | consumed_samples: 36\n",
      "Training epoch 0, iteration 18/99 | lr: 3e-05 | global_batch_size: 2 | global_step: 18 | reduced_train_loss: 1.289 | train_step_timing in s: 0.4294 | consumed_samples: 38\n",
      "Training epoch 0, iteration 19/99 | lr: 3e-05 | global_batch_size: 2 | global_step: 19 | reduced_train_loss: 1.273 | train_step_timing in s: 0.4304 | consumed_samples: 40\n",
      "Training epoch 0, iteration 20/99 | lr: 3e-05 | global_batch_size: 2 | global_step: 20 | reduced_train_loss: 0.6654 | train_step_timing in s: 0.4304 | consumed_samples: 42\n",
      "Training epoch 0, iteration 21/99 | lr: 3e-05 | global_batch_size: 2 | global_step: 21 | reduced_train_loss: 1.213 | train_step_timing in s: 0.4297 | consumed_samples: 44\n",
      "Training epoch 0, iteration 22/99 | lr: 3e-05 | global_batch_size: 2 | global_step: 22 | reduced_train_loss: 1.289 | train_step_timing in s: 0.4305 | consumed_samples: 46\n",
      "Training epoch 0, iteration 23/99 | lr: 3e-05 | global_batch_size: 2 | global_step: 23 | reduced_train_loss: 1.304 | train_step_timing in s: 0.4312 | consumed_samples: 48\n",
      "Training epoch 0, iteration 24/99 | lr: 3e-05 | global_batch_size: 2 | global_step: 24 | reduced_train_loss: 1.264 | train_step_timing in s: 0.4316 | consumed_samples: 50\n",
      "Training epoch 0, iteration 25/99 | lr: 3e-05 | global_batch_size: 2 | global_step: 25 | reduced_train_loss: 1.257 | train_step_timing in s: 0.4316 | consumed_samples: 52\n",
      "Training epoch 0, iteration 26/99 | lr: 3e-05 | global_batch_size: 2 | global_step: 26 | reduced_train_loss: 1.295 | train_step_timing in s: 0.4309 | consumed_samples: 54\n",
      "Training epoch 0, iteration 27/99 | lr: 3e-05 | global_batch_size: 2 | global_step: 27 | reduced_train_loss: 1.305 | train_step_timing in s: 0.4309 | consumed_samples: 56\n",
      "Training epoch 0, iteration 28/99 | lr: 3e-05 | global_batch_size: 2 | global_step: 28 | reduced_train_loss: 1.324 | train_step_timing in s: 0.4322 | consumed_samples: 58\n",
      "Training epoch 0, iteration 29/99 | lr: 3e-05 | global_batch_size: 2 | global_step: 29 | reduced_train_loss: 1.311 | train_step_timing in s: 0.4309 | consumed_samples: 60\n",
      "Training epoch 0, iteration 30/99 | lr: 3e-05 | global_batch_size: 2 | global_step: 30 | reduced_train_loss: 1.334 | train_step_timing in s: 0.4308 | consumed_samples: 62\n",
      "Training epoch 0, iteration 31/99 | lr: 3e-05 | global_batch_size: 2 | global_step: 31 | reduced_train_loss: 0.709 | train_step_timing in s: 0.4315 | consumed_samples: 64\n",
      "Training epoch 0, iteration 32/99 | lr: 3e-05 | global_batch_size: 2 | global_step: 32 | reduced_train_loss: 1.262 | train_step_timing in s: 0.4312 | consumed_samples: 66\n",
      "Training epoch 0, iteration 33/99 | lr: 3e-05 | global_batch_size: 2 | global_step: 33 | reduced_train_loss: 1.332 | train_step_timing in s: 0.4318 | consumed_samples: 68\n",
      "Training epoch 0, iteration 34/99 | lr: 3e-05 | global_batch_size: 2 | global_step: 34 | reduced_train_loss: 1.272 | train_step_timing in s: 0.4318 | consumed_samples: 70\n",
      "Training epoch 0, iteration 35/99 | lr: 3e-05 | global_batch_size: 2 | global_step: 35 | reduced_train_loss: 1.249 | train_step_timing in s: 0.4322 | consumed_samples: 72\n",
      "Training epoch 0, iteration 36/99 | lr: 3e-05 | global_batch_size: 2 | global_step: 36 | reduced_train_loss: 1.28 | train_step_timing in s: 0.4311 | consumed_samples: 74\n",
      "Training epoch 0, iteration 37/99 | lr: 3e-05 | global_batch_size: 2 | global_step: 37 | reduced_train_loss: 1.321 | train_step_timing in s: 0.4313 | consumed_samples: 76\n",
      "Training epoch 0, iteration 38/99 | lr: 3e-05 | global_batch_size: 2 | global_step: 38 | reduced_train_loss: 1.293 | train_step_timing in s: 0.4321 | consumed_samples: 78\n",
      "Training epoch 0, iteration 39/99 | lr: 3e-05 | global_batch_size: 2 | global_step: 39 | reduced_train_loss: 1.279 | train_step_timing in s: 0.4316 | consumed_samples: 80\n",
      "Training epoch 0, iteration 40/99 | lr: 3e-05 | global_batch_size: 2 | global_step: 40 | reduced_train_loss: 1.081 | train_step_timing in s: 0.4306 | consumed_samples: 82\n",
      "Training epoch 0, iteration 41/99 | lr: 3e-05 | global_batch_size: 2 | global_step: 41 | reduced_train_loss: 1.284 | train_step_timing in s: 0.4313 | consumed_samples: 84\n",
      "Training epoch 0, iteration 42/99 | lr: 3e-05 | global_batch_size: 2 | global_step: 42 | reduced_train_loss: 1.305 | train_step_timing in s: 0.4307 | consumed_samples: 86\n",
      "Training epoch 0, iteration 43/99 | lr: 3e-05 | global_batch_size: 2 | global_step: 43 | reduced_train_loss: 1.265 | train_step_timing in s: 0.4307 | consumed_samples: 88\n",
      "Training epoch 0, iteration 44/99 | lr: 3e-05 | global_batch_size: 2 | global_step: 44 | reduced_train_loss: 1.296 | train_step_timing in s: 0.4335 | consumed_samples: 90\n",
      "Training epoch 0, iteration 45/99 | lr: 3e-05 | global_batch_size: 2 | global_step: 45 | reduced_train_loss: 1.313 | train_step_timing in s: 0.4335 | consumed_samples: 92\n",
      "Training epoch 0, iteration 46/99 | lr: 3e-05 | global_batch_size: 2 | global_step: 46 | reduced_train_loss: 1.304 | train_step_timing in s: 0.4326 | consumed_samples: 94\n",
      "Training epoch 0, iteration 47/99 | lr: 3e-05 | global_batch_size: 2 | global_step: 47 | reduced_train_loss: 1.299 | train_step_timing in s: 0.4329 | consumed_samples: 96\n",
      "Training epoch 0, iteration 48/99 | lr: 3e-05 | global_batch_size: 2 | global_step: 48 | reduced_train_loss: 1.321 | train_step_timing in s: 0.4335 | consumed_samples: 98\n",
      "Training epoch 0, iteration 49/99 | lr: 3e-05 | global_batch_size: 2 | global_step: 49 | reduced_train_loss: 1.281 | train_step_timing in s: 0.4338 | consumed_samples: 100\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/lightning/pytorch/callbacks/model_checkpoint.py:384: `ModelCheckpoint(monitor='val_loss')` could not find the monitored key in the returned metrics: ['lr-McoreOpt/pg1', 'lr-McoreOpt/pg2', 'lr', 'global_batch_size', 'global_step', 'step', 'reduced_train_loss', 'grad_norm', 'num_zeros_in_grad', 'train_step_timing in s', 'consumed_samples', 'epoch']. HINT: Did you call `log('val_loss', value)` in the `LightningModule`?\n",
      "\n",
      "[INFO     | pytorch_lightning.utilities.rank_zero]: Epoch 0, global step 49: 'val_loss' was not in top 5\n",
      "[WARNING  | bitsandbytes.cextension]: Could not find the bitsandbytes CUDA binary at PosixPath('/usr/local/lib/python3.12/dist-packages/bitsandbytes/libbitsandbytes_cuda128.so')\n",
      "[WARNING  | bitsandbytes.cextension]: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "[NeMo W 2025-02-25 01:14:02 nemo_logging:405] /usr/local/lib/python3.12/dist-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "      warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n",
      "    \n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/selective_scan_interface.py:163: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @custom_fwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/selective_scan_interface.py:239: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @custom_bwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/triton/layer_norm.py:985: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @custom_fwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/triton/layer_norm.py:1044: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @custom_bwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/distributed/tensor_parallel.py:25: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @custom_fwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/distributed/tensor_parallel.py:61: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @custom_bwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/triton/ssd_combined.py:757: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @custom_fwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/triton/ssd_combined.py:835: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @custom_bwd\n",
      "\n",
      "[NeMo I 2025-02-25 01:14:17 nemo_logging:393] Scheduled async checkpoint save for /workspaces/bionemo-framework/docs/docs/user-guide/examples/bionemo-evo2/pretraining_demo/default--val_loss=0.0000-epoch=0-consumed_samples=100.0-last.ckpt\n",
      "Validation: iteration 1/20\n",
      "Validation: iteration 2/20\n",
      "Validation: iteration 3/20\n",
      "Validation: iteration 4/20\n",
      "Validation: iteration 5/20\n",
      "Validation: iteration 6/20\n",
      "Validation: iteration 7/20\n",
      "Validation: iteration 8/20\n",
      "Validation: iteration 9/20\n",
      "Validation: iteration 10/20\n",
      "Validation: iteration 11/20\n",
      "Validation: iteration 12/20\n",
      "Validation: iteration 13/20\n",
      "Validation: iteration 14/20\n",
      "Validation: iteration 15/20\n",
      "Validation: iteration 16/20\n",
      "Validation: iteration 17/20\n",
      "Validation: iteration 18/20\n",
      "Validation: iteration 19/20\n",
      "Validation: iteration 20/20\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('global_batch_size', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/lightning/pytorch/trainer/connectors/logger_connector/result.py:431: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "\n",
      "Training epoch 0, iteration 50/99 | lr: 3e-05 | global_batch_size: 2 | global_step: 50 | reduced_train_loss: 1.316 | train_step_timing in s: 0.4343 | consumed_samples: 102 | val_loss: 1.049\n",
      "Training epoch 0, iteration 51/99 | lr: 3e-05 | global_batch_size: 2 | global_step: 51 | reduced_train_loss: 1.151 | train_step_timing in s: 0.4323 | consumed_samples: 104 | val_loss: 1.049\n",
      "Training epoch 0, iteration 52/99 | lr: 3e-05 | global_batch_size: 2 | global_step: 52 | reduced_train_loss: 1.255 | train_step_timing in s: 0.432 | consumed_samples: 106 | val_loss: 1.049\n",
      "Training epoch 0, iteration 53/99 | lr: 3e-05 | global_batch_size: 2 | global_step: 53 | reduced_train_loss: 1.302 | train_step_timing in s: 0.4316 | consumed_samples: 108 | val_loss: 1.049\n",
      "Training epoch 0, iteration 54/99 | lr: 3e-05 | global_batch_size: 2 | global_step: 54 | reduced_train_loss: 1.315 | train_step_timing in s: 0.4319 | consumed_samples: 110 | val_loss: 1.049\n",
      "Training epoch 0, iteration 55/99 | lr: 3e-05 | global_batch_size: 2 | global_step: 55 | reduced_train_loss: 1.315 | train_step_timing in s: 0.4194 | consumed_samples: 112 | val_loss: 1.049\n",
      "Training epoch 0, iteration 56/99 | lr: 3e-05 | global_batch_size: 2 | global_step: 56 | reduced_train_loss: 1.302 | train_step_timing in s: 0.4328 | consumed_samples: 114 | val_loss: 1.049\n",
      "Training epoch 0, iteration 57/99 | lr: 3e-05 | global_batch_size: 2 | global_step: 57 | reduced_train_loss: 1.239 | train_step_timing in s: 0.4334 | consumed_samples: 116 | val_loss: 1.049\n",
      "Training epoch 0, iteration 58/99 | lr: 3e-05 | global_batch_size: 2 | global_step: 58 | reduced_train_loss: 1.325 | train_step_timing in s: 0.4343 | consumed_samples: 118 | val_loss: 1.049\n",
      "Training epoch 0, iteration 59/99 | lr: 3e-05 | global_batch_size: 2 | global_step: 59 | reduced_train_loss: 0.7567 | train_step_timing in s: 0.4317 | consumed_samples: 120 | val_loss: 1.049\n",
      "Training epoch 0, iteration 60/99 | lr: 3e-05 | global_batch_size: 2 | global_step: 60 | reduced_train_loss: 1.289 | train_step_timing in s: 0.432 | consumed_samples: 122 | val_loss: 1.049\n",
      "Training epoch 0, iteration 61/99 | lr: 3e-05 | global_batch_size: 2 | global_step: 61 | reduced_train_loss: 1.31 | train_step_timing in s: 0.4225 | consumed_samples: 124 | val_loss: 1.049\n",
      "Training epoch 0, iteration 62/99 | lr: 3e-05 | global_batch_size: 2 | global_step: 62 | reduced_train_loss: 1.255 | train_step_timing in s: 0.4342 | consumed_samples: 126 | val_loss: 1.049\n",
      "Training epoch 0, iteration 63/99 | lr: 3e-05 | global_batch_size: 2 | global_step: 63 | reduced_train_loss: 1.328 | train_step_timing in s: 0.4246 | consumed_samples: 128 | val_loss: 1.049\n",
      "Training epoch 0, iteration 64/99 | lr: 3e-05 | global_batch_size: 2 | global_step: 64 | reduced_train_loss: 1.222 | train_step_timing in s: 0.4377 | consumed_samples: 130 | val_loss: 1.049\n",
      "Training epoch 0, iteration 65/99 | lr: 3e-05 | global_batch_size: 2 | global_step: 65 | reduced_train_loss: 1.252 | train_step_timing in s: 0.4324 | consumed_samples: 132 | val_loss: 1.049\n",
      "Training epoch 0, iteration 66/99 | lr: 3e-05 | global_batch_size: 2 | global_step: 66 | reduced_train_loss: 1.288 | train_step_timing in s: 0.4327 | consumed_samples: 134 | val_loss: 1.049\n",
      "Training epoch 0, iteration 67/99 | lr: 3e-05 | global_batch_size: 2 | global_step: 67 | reduced_train_loss: 1.307 | train_step_timing in s: 0.4338 | consumed_samples: 136 | val_loss: 1.049\n",
      "[NeMo I 2025-02-25 01:14:27 nemo_logging:393] Async checkpoint save for step 50 (/workspaces/bionemo-framework/docs/docs/user-guide/examples/bionemo-evo2/pretraining_demo/default--val_loss=0.0000-epoch=0-consumed_samples=100.0-last.ckpt) finalized successfully.\n",
      "Training epoch 0, iteration 68/99 | lr: 3e-05 | global_batch_size: 2 | global_step: 68 | reduced_train_loss: 1.286 | train_step_timing in s: 0.4343 | consumed_samples: 138 | val_loss: 1.049\n",
      "Training epoch 0, iteration 69/99 | lr: 3e-05 | global_batch_size: 2 | global_step: 69 | reduced_train_loss: 1.321 | train_step_timing in s: 0.433 | consumed_samples: 140 | val_loss: 1.049\n",
      "Training epoch 0, iteration 70/99 | lr: 3e-05 | global_batch_size: 2 | global_step: 70 | reduced_train_loss: 1.286 | train_step_timing in s: 0.4332 | consumed_samples: 142 | val_loss: 1.049\n",
      "Training epoch 0, iteration 71/99 | lr: 3e-05 | global_batch_size: 2 | global_step: 71 | reduced_train_loss: 1.285 | train_step_timing in s: 0.4348 | consumed_samples: 144 | val_loss: 1.049\n",
      "Training epoch 0, iteration 72/99 | lr: 3e-05 | global_batch_size: 2 | global_step: 72 | reduced_train_loss: 0.7515 | train_step_timing in s: 0.4342 | consumed_samples: 146 | val_loss: 1.049\n",
      "Training epoch 0, iteration 73/99 | lr: 3e-05 | global_batch_size: 2 | global_step: 73 | reduced_train_loss: 1.365 | train_step_timing in s: 0.4333 | consumed_samples: 148 | val_loss: 1.049\n",
      "Training epoch 0, iteration 74/99 | lr: 3e-05 | global_batch_size: 2 | global_step: 74 | reduced_train_loss: 1.252 | train_step_timing in s: 0.4332 | consumed_samples: 150 | val_loss: 1.049\n",
      "Training epoch 0, iteration 75/99 | lr: 3e-05 | global_batch_size: 2 | global_step: 75 | reduced_train_loss: 1.265 | train_step_timing in s: 0.4338 | consumed_samples: 152 | val_loss: 1.049\n",
      "Training epoch 0, iteration 76/99 | lr: 3e-05 | global_batch_size: 2 | global_step: 76 | reduced_train_loss: 1.314 | train_step_timing in s: 0.4333 | consumed_samples: 154 | val_loss: 1.049\n",
      "Training epoch 0, iteration 77/99 | lr: 3e-05 | global_batch_size: 2 | global_step: 77 | reduced_train_loss: 1.298 | train_step_timing in s: 0.4341 | consumed_samples: 156 | val_loss: 1.049\n",
      "Training epoch 0, iteration 78/99 | lr: 3e-05 | global_batch_size: 2 | global_step: 78 | reduced_train_loss: 1.333 | train_step_timing in s: 0.4339 | consumed_samples: 158 | val_loss: 1.049\n",
      "Training epoch 0, iteration 79/99 | lr: 3e-05 | global_batch_size: 2 | global_step: 79 | reduced_train_loss: 1.291 | train_step_timing in s: 0.4348 | consumed_samples: 160 | val_loss: 1.049\n",
      "Training epoch 0, iteration 80/99 | lr: 3e-05 | global_batch_size: 2 | global_step: 80 | reduced_train_loss: 1.316 | train_step_timing in s: 0.4219 | consumed_samples: 162 | val_loss: 1.049\n",
      "Training epoch 0, iteration 81/99 | lr: 3e-05 | global_batch_size: 2 | global_step: 81 | reduced_train_loss: 1.335 | train_step_timing in s: 0.4347 | consumed_samples: 164 | val_loss: 1.049\n",
      "Training epoch 0, iteration 82/99 | lr: 3e-05 | global_batch_size: 2 | global_step: 82 | reduced_train_loss: 1.319 | train_step_timing in s: 0.434 | consumed_samples: 166 | val_loss: 1.049\n",
      "Training epoch 0, iteration 83/99 | lr: 3e-05 | global_batch_size: 2 | global_step: 83 | reduced_train_loss: 1.23 | train_step_timing in s: 0.434 | consumed_samples: 168 | val_loss: 1.049\n",
      "Training epoch 0, iteration 84/99 | lr: 3e-05 | global_batch_size: 2 | global_step: 84 | reduced_train_loss: 1.33 | train_step_timing in s: 0.4342 | consumed_samples: 170 | val_loss: 1.049\n",
      "Training epoch 0, iteration 85/99 | lr: 3e-05 | global_batch_size: 2 | global_step: 85 | reduced_train_loss: 1.316 | train_step_timing in s: 0.4351 | consumed_samples: 172 | val_loss: 1.049\n",
      "Training epoch 0, iteration 86/99 | lr: 3e-05 | global_batch_size: 2 | global_step: 86 | reduced_train_loss: 1.309 | train_step_timing in s: 0.4353 | consumed_samples: 174 | val_loss: 1.049\n",
      "Training epoch 0, iteration 87/99 | lr: 3e-05 | global_batch_size: 2 | global_step: 87 | reduced_train_loss: 1.19 | train_step_timing in s: 0.4353 | consumed_samples: 176 | val_loss: 1.049\n",
      "Training epoch 0, iteration 88/99 | lr: 3e-05 | global_batch_size: 2 | global_step: 88 | reduced_train_loss: 1.301 | train_step_timing in s: 0.4223 | consumed_samples: 178 | val_loss: 1.049\n",
      "Training epoch 0, iteration 89/99 | lr: 3e-05 | global_batch_size: 2 | global_step: 89 | reduced_train_loss: 1.327 | train_step_timing in s: 0.4385 | consumed_samples: 180 | val_loss: 1.049\n",
      "Training epoch 0, iteration 90/99 | lr: 3e-05 | global_batch_size: 2 | global_step: 90 | reduced_train_loss: 1.3 | train_step_timing in s: 0.4235 | consumed_samples: 182 | val_loss: 1.049\n",
      "Training epoch 0, iteration 91/99 | lr: 3e-05 | global_batch_size: 2 | global_step: 91 | reduced_train_loss: 1.278 | train_step_timing in s: 0.4357 | consumed_samples: 184 | val_loss: 1.049\n",
      "Training epoch 0, iteration 92/99 | lr: 3e-05 | global_batch_size: 2 | global_step: 92 | reduced_train_loss: 1.302 | train_step_timing in s: 0.4364 | consumed_samples: 186 | val_loss: 1.049\n",
      "Training epoch 0, iteration 93/99 | lr: 3e-05 | global_batch_size: 2 | global_step: 93 | reduced_train_loss: 1.094 | train_step_timing in s: 0.4364 | consumed_samples: 188 | val_loss: 1.049\n",
      "Training epoch 0, iteration 94/99 | lr: 3e-05 | global_batch_size: 2 | global_step: 94 | reduced_train_loss: 1.326 | train_step_timing in s: 0.4234 | consumed_samples: 190 | val_loss: 1.049\n",
      "Training epoch 0, iteration 95/99 | lr: 3e-05 | global_batch_size: 2 | global_step: 95 | reduced_train_loss: 1.176 | train_step_timing in s: 0.4366 | consumed_samples: 192 | val_loss: 1.049\n",
      "Training epoch 0, iteration 96/99 | lr: 3e-05 | global_batch_size: 2 | global_step: 96 | reduced_train_loss: 1.282 | train_step_timing in s: 0.4364 | consumed_samples: 194 | val_loss: 1.049\n",
      "Training epoch 0, iteration 97/99 | lr: 3e-05 | global_batch_size: 2 | global_step: 97 | reduced_train_loss: 1.293 | train_step_timing in s: 0.437 | consumed_samples: 196 | val_loss: 1.049\n",
      "Training epoch 0, iteration 98/99 | lr: 3e-05 | global_batch_size: 2 | global_step: 98 | reduced_train_loss: 1.313 | train_step_timing in s: 0.4363 | consumed_samples: 198 | val_loss: 1.049\n",
      "Training epoch 0, iteration 99/99 | lr: 3e-05 | global_batch_size: 2 | global_step: 99 | reduced_train_loss: 1.309 | train_step_timing in s: 0.4345 | consumed_samples: 200 | val_loss: 1.049\n",
      "[INFO     | pytorch_lightning.utilities.rank_zero]: Epoch 0, global step 99: 'val_loss' reached 1.04856 (best 1.04856), saving model to '/workspaces/bionemo-framework/docs/docs/user-guide/examples/bionemo-evo2/pretraining_demo/default--val_loss=1.0486-epoch=0-consumed_samples=200.0.ckpt' as top 5\n",
      "[NeMo I 2025-02-25 01:14:42 nemo_logging:393] Scheduled async checkpoint save for /workspaces/bionemo-framework/docs/docs/user-guide/examples/bionemo-evo2/pretraining_demo/default--val_loss=1.0486-epoch=0-consumed_samples=200.0.ckpt\n",
      "[NeMo I 2025-02-25 01:14:43 nemo_logging:393] Scheduled async checkpoint save for /workspaces/bionemo-framework/docs/docs/user-guide/examples/bionemo-evo2/pretraining_demo/default--val_loss=1.0486-epoch=0-consumed_samples=200.0-last.ckpt\n",
      "Validation: iteration 1/20\n",
      "Validation: iteration 2/20\n",
      "Validation: iteration 3/20\n",
      "Validation: iteration 4/20\n",
      "Validation: iteration 5/20\n",
      "Validation: iteration 6/20\n",
      "Validation: iteration 7/20\n",
      "Validation: iteration 8/20\n",
      "Validation: iteration 9/20\n",
      "Validation: iteration 10/20\n",
      "Validation: iteration 11/20\n",
      "Validation: iteration 12/20\n",
      "Validation: iteration 13/20\n",
      "Validation: iteration 14/20\n",
      "Validation: iteration 15/20\n",
      "Validation: iteration 16/20\n",
      "Validation: iteration 17/20\n",
      "Validation: iteration 18/20\n",
      "Validation: iteration 19/20\n",
      "Validation: iteration 20/20\n",
      "[INFO     | pytorch_lightning.utilities.rank_zero]: `Trainer.fit` stopped: `max_steps=100` reached.\n",
      "[NeMo I 2025-02-25 01:14:45 nemo_logging:393] Pending async checkpoint saves. Finalizing them synchronously now\n",
      "[NeMo I 2025-02-25 01:14:54 nemo_logging:393] Async checkpoint save for step 100 (/workspaces/bionemo-framework/docs/docs/user-guide/examples/bionemo-evo2/pretraining_demo/default--val_loss=1.0486-epoch=0-consumed_samples=200.0.ckpt) finalized successfully.\n",
      "[NeMo I 2025-02-25 01:14:54 nemo_logging:393] Async checkpoint save for step 100 (/workspaces/bionemo-framework/docs/docs/user-guide/examples/bionemo-evo2/pretraining_demo/default--val_loss=1.0486-epoch=0-consumed_samples=200.0-last.ckpt) finalized successfully.\n"
     ]
    }
   ],
   "source": [
    "# For evo2 training and fine-tuning follow the same set of steps, so we use the same train_evo2 command.\n",
    "#  the big difference is the --ckpt-dir argument which points to a pre-existing checkpoint from some other training run.\n",
    "!train_evo2 \\\n",
    "    -d training_data_config.yaml \\\n",
    "    --dataset-dir {preprocessed_data} \\\n",
    "    --experiment-dir pretraining_demo \\\n",
    "    --model-size 1b \\\n",
    "    --devices 1 \\\n",
    "    --num-nodes 1 \\\n",
    "    --seq-length 1024 \\\n",
    "    --micro-batch-size 2 \\\n",
    "    --lr 0.0001 \\\n",
    "    --warmup-steps 5 \\\n",
    "    --max-steps 100 \\\n",
    "    --ckpt-dir nemo2_evo2_1b_8k \\\n",
    "    --clip-grad 1 \\\n",
    "    --wd 0.01 \\\n",
    "    --activation-checkpoint-recompute-num-layers 1 \\\n",
    "    --val-check-interval 50 \\\n",
    "    --ckpt-async-save \\\n",
    "    --no-wandb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

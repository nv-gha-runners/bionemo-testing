{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zero-shot prediction of BRCA1 variant effects with Evo 2\n",
    "\n",
    "*Note - this notebook is a reproduction of The Arc Institute’s same-titled notebook [here](https://github.com/ArcInstitute/evo2/blob/main/notebooks/brca1/brca1_zero_shot_vep.ipynb), using the BioNeMo 2 implementation of Evo2.*\n",
    "\n",
    "The human *BRCA1* gene encodes for a protein that repairs damaged DNA ([Moynahan et al., 1999](https://www.cell.com/molecular-cell/fulltext/S1097-2765%2800%2980202-6)). Certain variants of this gene have been associated with an increased risk of breast and ovarian cancers ([Miki et al., 1994](https://www.science.org/doi/10.1126/science.7545954?url_ver=Z39.88-2003&rfr_id=ori:rid:crossref.org&rfr_dat=cr_pub%20%200pubmed)). Using Evo 2, we can predict whether a particular single nucleotide variant (SNV) of the *BRCA1* gene is likely to be harmful to the protein's function, and thus potentially increase the risk of cancer for the patient with the genetic variant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/lightning_utilities-0.12.0.dev0-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/looseversion-1.3.0-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/nvfuser-0.2.23a0+6627725-py3.12-linux-x86_64.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/opt_einsum-3.4.0-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/lightning_thunder-0.2.0.dev0-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Loading egg at /usr/local/lib/python3.12/dist-packages/dill-0.3.9-py3.12.egg is deprecated. pip 25.1 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: biopython in /usr/local/lib/python3.12/dist-packages (1.85)\n",
      "Requirement already satisfied: openpyxl in /usr/local/lib/python3.12/dist-packages (3.1.5)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from biopython) (1.26.4)\n",
      "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.12/dist-packages (from openpyxl) (2.0.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install biopython openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import gzip\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from Bio import SeqIO\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import roc_auc_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by loading a dataset from [Findlay et al. (2018)](https://www.nature.com/articles/s41586-018-0461-z), which contains experimentally measured function scores of 3,893 *BRCA1* SNVs. These function scores reflect the extent by which the genetic variant has disrupted the protein's function, with lower scores indicating greater disruption. In this dataset, the SNVs are classified into three categories based on their function scores: `LOF` (loss-of-function), `INT` (intermediate), and `FUNC` (functional). We start by reading in this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the data if not present\n",
    "if not os.path.exists('brca1'):\n",
    "    os.makedirs('brca1')\n",
    "\n",
    "commit_hash = \"3819474bee6c24938016614411f1fa025e542bbe\"\n",
    "\n",
    "if not os.path.exists(os.path.join('brca1', '41586_2018_461_MOESM3_ESM.xlsx')):\n",
    "    !wget https://github.com/ArcInstitute/evo2/raw/{commit_hash}/notebooks/brca1/41586_2018_461_MOESM3_ESM.xlsx -O brca1/41586_2018_461_MOESM3_ESM.xlsx\n",
    "\n",
    "if not os.path.exists(os.path.join('brca1', 'GRCh37.p13_chr17.fna.gz')):\n",
    "    !wget https://github.com/ArcInstitute/evo2/raw/{commit_hash}/notebooks/brca1/GRCh37.p13_chr17.fna.gz -O brca1/GRCh37.p13_chr17.fna.gz\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then group the `FUNC` and `INT` classes of SNVs together into a single category (`FUNC/INT`).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chrom</th>\n",
       "      <th>pos</th>\n",
       "      <th>ref</th>\n",
       "      <th>alt</th>\n",
       "      <th>score</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17</td>\n",
       "      <td>41276135</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>-0.372611</td>\n",
       "      <td>FUNC/INT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>41276135</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>-0.045313</td>\n",
       "      <td>FUNC/INT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17</td>\n",
       "      <td>41276135</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>-0.108254</td>\n",
       "      <td>FUNC/INT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17</td>\n",
       "      <td>41276134</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>-0.277963</td>\n",
       "      <td>FUNC/INT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>41276134</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>-0.388414</td>\n",
       "      <td>FUNC/INT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>17</td>\n",
       "      <td>41276134</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>-0.280973</td>\n",
       "      <td>FUNC/INT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>17</td>\n",
       "      <td>41276133</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>-0.973683</td>\n",
       "      <td>FUNC/INT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>17</td>\n",
       "      <td>41276133</td>\n",
       "      <td>C</td>\n",
       "      <td>G</td>\n",
       "      <td>-0.373489</td>\n",
       "      <td>FUNC/INT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>17</td>\n",
       "      <td>41276133</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>0.006314</td>\n",
       "      <td>FUNC/INT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>17</td>\n",
       "      <td>41276132</td>\n",
       "      <td>A</td>\n",
       "      <td>T</td>\n",
       "      <td>-0.207552</td>\n",
       "      <td>FUNC/INT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   chrom       pos ref alt     score     class\n",
       "0     17  41276135   T   G -0.372611  FUNC/INT\n",
       "1     17  41276135   T   C -0.045313  FUNC/INT\n",
       "2     17  41276135   T   A -0.108254  FUNC/INT\n",
       "3     17  41276134   T   G -0.277963  FUNC/INT\n",
       "4     17  41276134   T   C -0.388414  FUNC/INT\n",
       "5     17  41276134   T   A -0.280973  FUNC/INT\n",
       "6     17  41276133   C   T -0.973683  FUNC/INT\n",
       "7     17  41276133   C   G -0.373489  FUNC/INT\n",
       "8     17  41276133   C   A  0.006314  FUNC/INT\n",
       "9     17  41276132   A   T -0.207552  FUNC/INT"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brca1_df = pd.read_excel(\n",
    "    os.path.join('brca1', '41586_2018_461_MOESM3_ESM.xlsx'),\n",
    "    header=2,\n",
    ")\n",
    "brca1_df = brca1_df[[\n",
    "    'chromosome', 'position (hg19)', 'reference', 'alt', 'function.score.mean', 'func.class',\n",
    "]]\n",
    "\n",
    "# Rename columns\n",
    "brca1_df.rename(columns={\n",
    "    'chromosome': 'chrom',\n",
    "    'position (hg19)': 'pos',\n",
    "    'reference': 'ref',\n",
    "    'alt': 'alt',\n",
    "    'function.score.mean': 'score',\n",
    "    'func.class': 'class',\n",
    "}, inplace=True)\n",
    "\n",
    "# Convert to two-class system\n",
    "brca1_df['class'] = brca1_df['class'].replace(['FUNC', 'INT'], 'FUNC/INT')\n",
    "\n",
    "brca1_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We build a function to parse the reference and variant sequences of a 8,192-bp window around the genomic position of each SNV, using the reference sequence of human chromosome 17 where *BRCA1* is located.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_SIZE = 8192\n",
    "\n",
    "# Read the reference genome sequence of chromosome 17\n",
    "with gzip.open(os.path.join('brca1', 'GRCh37.p13_chr17.fna.gz'), \"rt\") as handle:\n",
    "    for record in SeqIO.parse(handle, \"fasta\"):\n",
    "        seq_chr17 = str(record.seq)\n",
    "        break\n",
    "\n",
    "def parse_sequences(pos, ref, alt):\n",
    "    \"\"\"\n",
    "    Parse reference and variant sequences from the reference genome sequence.\n",
    "    \"\"\"\n",
    "    p = pos - 1 # Convert to 0-indexed position\n",
    "    full_seq = seq_chr17\n",
    "\n",
    "    ref_seq_start = max(0, p - WINDOW_SIZE//2)\n",
    "    ref_seq_end = min(len(full_seq), p + WINDOW_SIZE//2)\n",
    "    ref_seq = seq_chr17[ref_seq_start:ref_seq_end]\n",
    "    snv_pos_in_ref = min(WINDOW_SIZE//2, p)\n",
    "    var_seq = ref_seq[:snv_pos_in_ref] + alt + ref_seq[snv_pos_in_ref+1:]\n",
    "\n",
    "    # Sanity checks\n",
    "    assert len(var_seq) == len(ref_seq)\n",
    "    assert ref_seq[snv_pos_in_ref] == ref\n",
    "    assert var_seq[snv_pos_in_ref] == alt\n",
    "\n",
    "    return ref_seq, var_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make things run faster, we'll just look at a balanced sample of our data. If you want to run on the full dataset, set `disable_sample=True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(330, 6)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disable_sample = False\n",
    "SAMPLE_FRAC = 0.2\n",
    "balanced_sample = True\n",
    "\n",
    "random_state = 42\n",
    "if not disable_sample:\n",
    "    if balanced_sample:\n",
    "        # Get the number of rows in the dataframe\n",
    "        num_rows_minor_class = math.ceil(len(brca1_df[brca1_df['class'] == 'LOF']) * SAMPLE_FRAC)\n",
    "        brca1_df = pd.concat([\n",
    "            brca1_df[brca1_df['class'] == 'LOF'].sample(n=num_rows_minor_class, random_state=random_state),\n",
    "            brca1_df[brca1_df['class'] == 'FUNC/INT'].sample(n=num_rows_minor_class, random_state=random_state)\n",
    "        ]).sample(frac=1.0, random_state=random_state).reset_index(drop=True)\n",
    "    else:\n",
    "        # Calculate the number of rows to sample\n",
    "        num_rows_to_sample = int(len(brca1_df) * SAMPLE_FRAC)\n",
    "        brca1_df = brca1_df.sample(frac=SAMPLE_FRAC, random_state=random_state).reset_index(drop=True)\n",
    "brca1_df.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll write these to local `.fasta` files so we can use them for prediction below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique reference sequences: 296\n",
      "Total unique variant sequences: 330\n"
     ]
    }
   ],
   "source": [
    "# Create output directory\n",
    "output_dir = Path(\"brca1_fasta_files\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save reference and variant sequences to FASTA\n",
    "ref_fasta_path = output_dir / \"brca1_reference_sequences.fasta\"\n",
    "var_fasta_path = output_dir / \"brca1_variant_sequences.fasta\"\n",
    "\n",
    "# Track unique sequences\n",
    "ref_sequences = set()\n",
    "var_sequences = set()\n",
    "ref_seq_to_name = {}\n",
    "# Store unique sequences with metadata for writing\n",
    "ref_entries = []\n",
    "var_entries = []\n",
    "ref_names = []\n",
    "var_names = []\n",
    "# Collect unique reference and variant sequences\n",
    "for idx, row in brca1_df.iterrows():\n",
    "    ref_seq, var_seq = parse_sequences(row['pos'], row['ref'], row['alt'])\n",
    "\n",
    "    # Add to sets to ensure uniqueness\n",
    "    if ref_seq not in ref_sequences:\n",
    "        ref_sequences.add(ref_seq)\n",
    "        ref_name = f\"BRCA1_ref_pos_{row['pos']}_{row['ref']}_class_{row['class']}\"\n",
    "\n",
    "        ref_entries.append(\n",
    "            f\">{ref_name}\\n{ref_seq}\\n\"\n",
    "        )\n",
    "        ref_names.append(ref_name)\n",
    "        ref_seq_to_name[ref_seq] = ref_name\n",
    "    else:\n",
    "        ref_name = ref_seq_to_name[ref_seq]\n",
    "        ref_names.append(ref_name)\n",
    "    if var_seq not in var_sequences:\n",
    "        var_sequences.add(var_seq)\n",
    "        var_name = f\"BRCA1_var_pos_{row['pos']}_{row['ref']}to{row['alt']}_class_{row['class']}\"\n",
    "\n",
    "        var_entries.append(\n",
    "            f\">{var_name}\\n{var_seq}\\n\"\n",
    "        )\n",
    "        var_names.append(var_name)\n",
    "    else:\n",
    "        assert False, \"Duplicate variant sequence\"\n",
    "\n",
    "# Write unique sequences to FASTA files\n",
    "with open(ref_fasta_path, \"w\") as f:\n",
    "    f.writelines(ref_entries)\n",
    "\n",
    "with open(var_fasta_path, \"w\") as f:\n",
    "    f.writelines(var_entries)\n",
    "\n",
    "\n",
    "brca1_df['ref_fasta_name'] = ref_names\n",
    "brca1_df['var_fasta_name'] = var_names\n",
    "\n",
    "# Print counts\n",
    "print(f\"Total unique reference sequences: {len(ref_sequences)}\")\n",
    "print(f\"Total unique variant sequences: {len(var_sequences)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Then, we load Evo 2 1B model, loading the Evo 2 weights from hugging face.\n",
    "\n",
    "*Note - for better performance, load the 7b model by setting `MODEL_SIZE=\"7b\"` which also works well GPUs that do not support FP8.*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint directory is not empty. Skipping command.\n"
     ]
    }
   ],
   "source": [
    "MODEL_SIZE = \"1b\"  # also try 7b if you have a GPU with more than 32GB of memory\n",
    "# Define checkpoint path\n",
    "checkpoint_path = Path(f\"nemo2_evo2_{MODEL_SIZE}_8k\")\n",
    "\n",
    "# Check if the directory does not exist or is empty\n",
    "if not checkpoint_path.exists() or not any(checkpoint_path.iterdir()):\n",
    "    !evo2_convert_to_nemo2 --model-path hf://arcinstitute/savanna_evo2_1b_base --model-size {MODEL_SIZE} --output-dir nemo2_evo2_{MODEL_SIZE}_8k\n",
    "else:\n",
    "    print(\"Checkpoint directory is not empty. Skipping command.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we score the likelihoods of the reference and variant sequences of each SNV.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FP8 Support: True\n",
      "Device: NVIDIA RTX 6000 Ada Generation, Compute Capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "# Define output directories for prediction results\n",
    "predict_ref_dir = output_dir / \"reference_predictions\"\n",
    "predict_var_dir = output_dir / \"variant_predictions\"\n",
    "predict_ref_dir.mkdir(parents=True, exist_ok=True)\n",
    "predict_var_dir.mkdir(parents=True, exist_ok=True)\n",
    "# Check if FP8 is supported on the current GPU\n",
    "import torch\n",
    "\n",
    "def check_fp8_support():\n",
    "    \"\"\"\n",
    "    Check if FP8 is supported on the current GPU.\n",
    "    FP8 requires compute capability 8.9+ (Ada Lovelace/Hopper architecture or newer).\n",
    "    \"\"\"\n",
    "    if not torch.cuda.is_available():\n",
    "        return False, \"CUDA not available\"\n",
    "    \n",
    "    device_props = torch.cuda.get_device_properties(0)\n",
    "    compute_capability = f\"{device_props.major}.{device_props.minor}\"\n",
    "    device_name = device_props.name\n",
    "    \n",
    "    # FP8 is supported on compute capability 8.9+ (Ada Lovelace/Hopper architecture)\n",
    "    is_supported = (device_props.major > 8) or (device_props.major == 8 and device_props.minor >= 9)\n",
    "    \n",
    "    return is_supported, f\"Device: {device_name}, Compute Capability: {compute_capability}\"\n",
    "\n",
    "fp8_supported, gpu_info = check_fp8_support()\n",
    "print(f\"FP8 Support: {fp8_supported}\")\n",
    "print(gpu_info)\n",
    "\n",
    "# Note: If FP8 is not supported, you may want to disable it in the model config\n",
    "# The Evo2 config has 'use_fp8_input_projections: True' by default\n",
    "\n",
    "fp8_option = \"--fp8\" if fp8_supported else \"\"\n",
    "\n",
    "# Update predict commands to run on the full dataset\n",
    "predict_ref_command = (\n",
    "    f\"predict_evo2 --fasta {ref_fasta_path} --ckpt-dir {checkpoint_path} \"\n",
    "    f\"--output-dir {predict_ref_dir} --model-size {MODEL_SIZE} --tensor-parallel-size 1 \"\n",
    "    f\"--pipeline-model-parallel-size 1 --context-parallel-size 1 --output-log-prob-seqs {fp8_option}\"\n",
    ")\n",
    "\n",
    "predict_var_command = (\n",
    "    f\"predict_evo2 --fasta {var_fasta_path} --ckpt-dir {checkpoint_path} \"\n",
    "    f\"--output-dir {predict_var_dir} --model-size {MODEL_SIZE} --tensor-parallel-size 1 \"\n",
    "    f\"--pipeline-model-parallel-size 1 --context-parallel-size 1 --output-log-prob-seqs {fp8_option}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running command: predict_evo2 --fasta brca1_fasta_files/brca1_reference_sequences.fasta --ckpt-dir nemo2_evo2_1b_8k --output-dir brca1_fasta_files/reference_predictions --model-size 1b --tensor-parallel-size 1 --pipeline-model-parallel-size 1 --context-parallel-size 1 --output-log-prob-seqs --fp8\n",
      "[WARNING  | bitsandbytes.cextension]: Could not find the bitsandbytes CUDA binary at PosixPath('/usr/local/lib/python3.12/dist-packages/bitsandbytes/libbitsandbytes_cuda128.so')\n",
      "[WARNING  | bitsandbytes.cextension]: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "[NeMo W 2025-03-04 01:01:10 nemo_logging:405] /usr/local/lib/python3.12/dist-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "      warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n",
      "    \n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/selective_scan_interface.py:163: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @custom_fwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/selective_scan_interface.py:239: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @custom_bwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/triton/layer_norm.py:985: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @custom_fwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/triton/layer_norm.py:1044: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @custom_bwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/distributed/tensor_parallel.py:25: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @custom_fwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/distributed/tensor_parallel.py:61: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @custom_bwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/triton/ssd_combined.py:757: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @custom_fwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/triton/ssd_combined.py:835: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @custom_bwd\n",
      "\n",
      "[INFO     | pytorch_lightning.utilities.rank_zero]: GPU available: True (cuda), used: True\n",
      "[INFO     | pytorch_lightning.utilities.rank_zero]: TPU available: False, using: 0 TPU cores\n",
      "[INFO     | pytorch_lightning.utilities.rank_zero]: HPU available: False, using: 0 HPUs\n",
      "[NeMo W 2025-03-04 01:01:11 nemo_logging:405] No version folders would be created under the log folder as 'resume_if_exists' is enabled.\n",
      "[NeMo I 2025-03-04 01:01:11 nemo_logging:393] Experiments will be logged at /tmp/tmpupzx4lk1/default\n",
      "[NeMo W 2025-03-04 01:01:11 nemo_logging:405] \"update_logger_directory\" is True. Overwriting tensorboard logger \"save_dir\" to /tmp/tmpupzx4lk1\n",
      "[NeMo I 2025-03-04 01:01:11 nemo_logging:393] Using byte-level tokenization\n",
      "[NeMo I 2025-03-04 01:01:11 nemo_logging:393] Rank 0 has data parallel group : [0]\n",
      "[NeMo I 2025-03-04 01:01:11 nemo_logging:393] Rank 0 has combined group of data parallel and context parallel : [0]\n",
      "[NeMo I 2025-03-04 01:01:11 nemo_logging:393] All data parallel group ranks with context parallel combined: [[0]]\n",
      "[NeMo I 2025-03-04 01:01:11 nemo_logging:393] Ranks 0 has data parallel rank: 0\n",
      "[NeMo I 2025-03-04 01:01:11 nemo_logging:393] Rank 0 has context parallel group: [0]\n",
      "[NeMo I 2025-03-04 01:01:11 nemo_logging:393] All context parallel group ranks: [[0]]\n",
      "[NeMo I 2025-03-04 01:01:11 nemo_logging:393] Ranks 0 has context parallel rank: 0\n",
      "[NeMo I 2025-03-04 01:01:11 nemo_logging:393] Rank 0 has model parallel group: [0]\n",
      "[NeMo I 2025-03-04 01:01:11 nemo_logging:393] All model parallel group ranks: [[0]]\n",
      "[NeMo I 2025-03-04 01:01:11 nemo_logging:393] Rank 0 has tensor model parallel group: [0]\n",
      "[NeMo I 2025-03-04 01:01:11 nemo_logging:393] All tensor model parallel group ranks: [[0]]\n",
      "[NeMo I 2025-03-04 01:01:11 nemo_logging:393] Rank 0 has tensor model parallel rank: 0\n",
      "[NeMo I 2025-03-04 01:01:11 nemo_logging:393] Rank 0 has pipeline model parallel group: [0]\n",
      "[NeMo I 2025-03-04 01:01:11 nemo_logging:393] Rank 0 has embedding group: [0]\n",
      "[NeMo I 2025-03-04 01:01:11 nemo_logging:393] All pipeline model parallel group ranks: [[0]]\n",
      "[NeMo I 2025-03-04 01:01:11 nemo_logging:393] Rank 0 has pipeline model parallel rank 0\n",
      "[NeMo I 2025-03-04 01:01:11 nemo_logging:393] All embedding group ranks: [[0]]\n",
      "[NeMo I 2025-03-04 01:01:11 nemo_logging:393] Rank 0 has embedding rank: 0\n",
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1\n",
      "[INFO     | pytorch_lightning.utilities.rank_zero]: ----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 1 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[NeMo I 2025-03-04 01:01:11 num_microbatches_calculator:228] setting number of microbatches to constant 1\n",
      "[NeMo I 2025-03-04 01:01:11 nemo_logging:393] Padded vocab_size: 512, original vocab_size: 512, dummy tokens: 0.\n",
      "[NeMo W 2025-03-04 01:01:11 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-03-04 01:01:11 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-03-04 01:01:11 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-03-04 01:01:11 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-03-04 01:01:11 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-03-04 01:01:11 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-03-04 01:01:11 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-03-04 01:01:11 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-03-04 01:01:11 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-03-04 01:01:11 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-03-04 01:01:11 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-03-04 01:01:11 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-03-04 01:01:11 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-03-04 01:01:11 random:220] CPU RNG state changed within GPU RNG context\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "[NeMo W 2025-03-04 01:01:11 nemo_logging:405] Could not copy Trainer's 'max_steps' to LR scheduler's 'max_steps'. If you are not using an LR scheduler, this warning can safely be ignored.\n",
      "[NeMo I 2025-03-04 01:01:11 nemo_logging:393]  > number of parameters on (tensor, pipeline) model parallel rank (0 ,0): 1108204800\n",
      "[NeMo I 2025-03-04 01:01:11 utils:302] Setting up DistributedDataParallel with config DistributedDataParallelConfig(grad_reduce_in_fp32=False, overlap_grad_reduce=False, overlap_param_gather=False, align_param_gather=False, use_distributed_optimizer=False, num_distributed_optimizer_instances=1, check_for_nan_in_grad=True, check_for_large_grads=False, bucket_size=None, average_in_collective=False, fp8_param_gather=False)\n",
      "[NeMo I 2025-03-04 01:01:11 utils:323] Number of buckets for gradient all-reduce / reduce-scatter: 1\n",
      "    Params for bucket 1 (1108204800 elements):\n",
      "    \tmodule.decoder.layers.22.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.19.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.16.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.11.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.9.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.6.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.3.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.0.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.23.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.20.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.15.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.12.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.10.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.8.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.5.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.2.mixer.mixer.filter.R\n",
      "    \tmodule.decoder.layers.1.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.23.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.22.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.18.mixer.mixer.short_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.11.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.10.self_attention.linear_proj.bias\n",
      "    \tmodule.decoder.layers.8.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.6.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.3.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.22.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.16.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.9.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.7.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.5.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.4.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.0.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.23.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.13.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.10.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.8.mixer.mixer.filter.h\n",
      "    \tmodule.decoder.layers.6.mixer.mixer.filter.R\n",
      "    \tmodule.decoder.layers.3.self_attention.linear_proj.bias\n",
      "    \tmodule.decoder.layers.2.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.1.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.24.self_attention.linear_qkv.weight\n",
      "    \tmodule.decoder.layers.22.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.19.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.16.mixer.mixer.filter.p\n",
      "    \tmodule.decoder.layers.14.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.12.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.3.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.0.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.23.mixer.mixer.filter.R\n",
      "    \tmodule.decoder.layers.21.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.15.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.12.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.10.self_attention.linear_qkv.layer_norm_weight\n",
      "    \tmodule.decoder.layers.8.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.6.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.2.mixer.mixer.filter.p\n",
      "    \tmodule.decoder.final_norm.weight\n",
      "    \tmodule.decoder.layers.21.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.16.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.13.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.11.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.9.mixer.mixer.filter.gamma\n",
      "    \tmodule.decoder.layers.3.self_attention.linear_qkv.layer_norm_weight\n",
      "    \tmodule.decoder.layers.2.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.24.self_attention.linear_proj.bias\n",
      "    \tmodule.decoder.layers.23.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.20.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.19.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.16.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.15.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.12.mixer.mixer.filter.h\n",
      "    \tmodule.decoder.layers.10.self_attention.linear_proj.weight\n",
      "    \tmodule.decoder.layers.7.mixer.mixer.short_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.5.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.21.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.18.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.15.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.6.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.2.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.2.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.20.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.19.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.16.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.12.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.9.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.5.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.4.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.2.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.17.self_attention.linear_qkv.weight\n",
      "    \tmodule.decoder.layers.23.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.20.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.15.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.13.mixer.mixer.filter.gamma\n",
      "    \tmodule.decoder.layers.8.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.5.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.2.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.21.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.19.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.16.mixer.mixer.filter.R\n",
      "    \tmodule.decoder.layers.14.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.11.mixer.mixer.short_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.0.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.22.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.20.mixer.mixer.filter.p\n",
      "    \tmodule.decoder.layers.19.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.18.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.14.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.9.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.5.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.4.mixer.mixer.short_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.1.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.21.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.16.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.13.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.6.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.1.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.24.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.21.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.19.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.14.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.12.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.9.mixer.mixer.filter.p\n",
      "    \tmodule.decoder.layers.7.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.4.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.0.mixer.mixer.short_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.23.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.20.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.18.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.14.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.8.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.5.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.1.mixer.mixer.filter.h\n",
      "    \tmodule.decoder.layers.24.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.22.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.18.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.16.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.13.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.9.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.6.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.2.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.0.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.22.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.20.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.20.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.14.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.9.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.8.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.5.mixer.mixer.filter.h\n",
      "    \tmodule.decoder.layers.23.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.21.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.20.mixer.mixer.filter.gamma\n",
      "    \tmodule.decoder.layers.18.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.15.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.13.mixer.mixer.filter.p\n",
      "    \tmodule.decoder.layers.11.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.8.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.1.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.24.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.22.mixer.mixer.filter.h\n",
      "    \tmodule.decoder.layers.20.mixer.mixer.filter.R\n",
      "    \tmodule.decoder.layers.14.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.12.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.9.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.5.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.4.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.17.self_attention.linear_proj.bias\n",
      "    \tmodule.decoder.layers.17.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.13.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.10.self_attention.linear_qkv.weight\n",
      "    \tmodule.decoder.layers.8.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.6.mixer.mixer.filter.gamma\n",
      "    \tmodule.decoder.layers.24.self_attention.linear_qkv.layer_norm_weight\n",
      "    \tmodule.decoder.layers.22.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.18.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.16.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.13.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.12.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.9.mixer.mixer.filter.R\n",
      "    \tmodule.decoder.layers.7.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.3.self_attention.linear_qkv.weight\n",
      "    \tmodule.decoder.layers.0.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.23.mixer.mixer.filter.gamma\n",
      "    \tmodule.decoder.layers.17.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.15.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.12.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.11.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.7.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.1.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.24.self_attention.linear_proj.weight\n",
      "    \tmodule.decoder.layers.21.mixer.mixer.short_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.18.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.15.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.13.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.9.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.6.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.1.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.20.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.16.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.14.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.12.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.7.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.5.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.4.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.23.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.17.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.15.mixer.mixer.filter.h\n",
      "    \tmodule.decoder.layers.13.mixer.mixer.filter.R\n",
      "    \tmodule.decoder.layers.11.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.7.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.2.mixer.dense.weight\n",
      "    \tmodule.embedding.word_embeddings.weight\n",
      "    \tmodule.decoder.layers.22.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.19.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.11.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.9.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.6.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.4.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.0.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.19.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.17.self_attention.linear_qkv.layer_norm_weight\n",
      "    \tmodule.decoder.layers.15.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.13.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.7.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.4.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.2.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.1.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.23.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.18.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.16.mixer.mixer.filter.gamma\n",
      "    \tmodule.decoder.layers.11.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.8.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.6.mixer.mixer.filter.p\n",
      "    \tmodule.decoder.layers.3.self_attention.linear_proj.weight\n",
      "    \tmodule.decoder.layers.2.mixer.mixer.filter.gamma\n",
      "    \tmodule.decoder.layers.0.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.20.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.19.mixer.mixer.filter.h\n",
      "    \tmodule.decoder.layers.17.self_attention.linear_proj.weight\n",
      "    \tmodule.decoder.layers.14.mixer.mixer.short_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.7.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.4.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.1.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.23.mixer.mixer.filter.p\n",
      "    \tmodule.decoder.layers.21.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.13.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.10.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.6.mixer.hyena_proj_conv.short_conv_weight\n",
      "[NeMo I 2025-03-04 01:01:11 nemo_logging:393] Doing selective restore from RestoreConfig(path='nemo2_evo2_1b_8k', adapter_path=None, load_model_state=True, load_optim_state=False, load_artifacts=False)\n",
      "[NeMo I 2025-03-04 01:01:11 nemo_logging:393] Using <megatron.core.dist_checkpointing.strategies.fully_parallel.FullyParallelLoadStrategyWrapper object at 0x7330b1b9bec0> dist-ckpt load strategy.\n",
      "[WARNING  | py.warnings        ]: /workspaces/bionemo-framework/3rdparty/Megatron-LM/megatron/core/dist_checkpointing/strategies/torch.py:847: FutureWarning: `load_state_dict` is deprecated and will be removed in future versions. Please use `load` instead.\n",
      "  checkpoint.load_state_dict(\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/torch/distributed/checkpoint/planner_helpers.py:316: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.\n",
      "  device = getattr(value, \"device\", None)\n",
      "\n",
      "[NeMo I 2025-03-04 01:01:12 nemo_logging:393] Global Checkpoint Load : Rank : 0 : Start time : 1741050071.495s : Time spent in load_checkpoint: 0.932s\n",
      "[NeMo I 2025-03-04 01:01:12 nemo_logging:393] Restoring model weights from RestoreConfig(path='nemo2_evo2_1b_8k', adapter_path=None, load_model_state=True, load_optim_state=False, load_artifacts=False)\n",
      "[NeMo I 2025-03-04 01:01:12 nemo_logging:393] Finished restoring from RestoreConfig(path='nemo2_evo2_1b_8k', adapter_path=None, load_model_state=True, load_optim_state=False, load_artifacts=False), cleaning up.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Running command: {predict_ref_command}\")\n",
    "!{predict_ref_command}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict variant seqs (sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running command: predict_evo2 --fasta brca1_fasta_files/brca1_variant_sequences.fasta --ckpt-dir nemo2_evo2_1b_8k --output-dir brca1_fasta_files/variant_predictions --model-size 1b --tensor-parallel-size 1 --pipeline-model-parallel-size 1 --context-parallel-size 1 --output-log-prob-seqs --fp8\n",
      "[WARNING  | bitsandbytes.cextension]: Could not find the bitsandbytes CUDA binary at PosixPath('/usr/local/lib/python3.12/dist-packages/bitsandbytes/libbitsandbytes_cuda128.so')\n",
      "[WARNING  | bitsandbytes.cextension]: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "[NeMo W 2025-03-04 01:02:34 nemo_logging:405] /usr/local/lib/python3.12/dist-packages/pydub/utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "      warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n",
      "    \n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/selective_scan_interface.py:163: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @custom_fwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/selective_scan_interface.py:239: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @custom_bwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/triton/layer_norm.py:985: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @custom_fwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/triton/layer_norm.py:1044: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @custom_bwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/distributed/tensor_parallel.py:25: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @custom_fwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/distributed/tensor_parallel.py:61: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @custom_bwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/triton/ssd_combined.py:757: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @custom_fwd\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/triton/ssd_combined.py:835: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  @custom_bwd\n",
      "\n",
      "[INFO     | pytorch_lightning.utilities.rank_zero]: GPU available: True (cuda), used: True\n",
      "[INFO     | pytorch_lightning.utilities.rank_zero]: TPU available: False, using: 0 TPU cores\n",
      "[INFO     | pytorch_lightning.utilities.rank_zero]: HPU available: False, using: 0 HPUs\n",
      "[NeMo W 2025-03-04 01:02:35 nemo_logging:405] No version folders would be created under the log folder as 'resume_if_exists' is enabled.\n",
      "[NeMo I 2025-03-04 01:02:35 nemo_logging:393] Experiments will be logged at /tmp/tmpf9avvfzw/default\n",
      "[NeMo W 2025-03-04 01:02:35 nemo_logging:405] \"update_logger_directory\" is True. Overwriting tensorboard logger \"save_dir\" to /tmp/tmpf9avvfzw\n",
      "[NeMo I 2025-03-04 01:02:35 nemo_logging:393] Using byte-level tokenization\n",
      "[NeMo I 2025-03-04 01:02:35 nemo_logging:393] Rank 0 has data parallel group : [0]\n",
      "[NeMo I 2025-03-04 01:02:35 nemo_logging:393] Rank 0 has combined group of data parallel and context parallel : [0]\n",
      "[NeMo I 2025-03-04 01:02:35 nemo_logging:393] All data parallel group ranks with context parallel combined: [[0]]\n",
      "[NeMo I 2025-03-04 01:02:35 nemo_logging:393] Ranks 0 has data parallel rank: 0\n",
      "[NeMo I 2025-03-04 01:02:35 nemo_logging:393] Rank 0 has context parallel group: [0]\n",
      "[NeMo I 2025-03-04 01:02:35 nemo_logging:393] All context parallel group ranks: [[0]]\n",
      "[NeMo I 2025-03-04 01:02:35 nemo_logging:393] Ranks 0 has context parallel rank: 0\n",
      "[NeMo I 2025-03-04 01:02:35 nemo_logging:393] Rank 0 has model parallel group: [0]\n",
      "[NeMo I 2025-03-04 01:02:35 nemo_logging:393] All model parallel group ranks: [[0]]\n",
      "[NeMo I 2025-03-04 01:02:35 nemo_logging:393] Rank 0 has tensor model parallel group: [0]\n",
      "[NeMo I 2025-03-04 01:02:35 nemo_logging:393] All tensor model parallel group ranks: [[0]]\n",
      "[NeMo I 2025-03-04 01:02:35 nemo_logging:393] Rank 0 has tensor model parallel rank: 0\n",
      "[NeMo I 2025-03-04 01:02:35 nemo_logging:393] Rank 0 has pipeline model parallel group: [0]\n",
      "[NeMo I 2025-03-04 01:02:35 nemo_logging:393] Rank 0 has embedding group: [0]\n",
      "[NeMo I 2025-03-04 01:02:35 nemo_logging:393] All pipeline model parallel group ranks: [[0]]\n",
      "[NeMo I 2025-03-04 01:02:35 nemo_logging:393] Rank 0 has pipeline model parallel rank 0\n",
      "[NeMo I 2025-03-04 01:02:35 nemo_logging:393] All embedding group ranks: [[0]]\n",
      "[NeMo I 2025-03-04 01:02:35 nemo_logging:393] Rank 0 has embedding rank: 0\n",
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1\n",
      "[INFO     | pytorch_lightning.utilities.rank_zero]: ----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 1 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "[NeMo I 2025-03-04 01:02:35 num_microbatches_calculator:228] setting number of microbatches to constant 1\n",
      "[NeMo I 2025-03-04 01:02:35 nemo_logging:393] Padded vocab_size: 512, original vocab_size: 512, dummy tokens: 0.\n",
      "[NeMo W 2025-03-04 01:02:35 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-03-04 01:02:35 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-03-04 01:02:35 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-03-04 01:02:35 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-03-04 01:02:35 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-03-04 01:02:35 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-03-04 01:02:35 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-03-04 01:02:35 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-03-04 01:02:35 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-03-04 01:02:35 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-03-04 01:02:35 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-03-04 01:02:35 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-03-04 01:02:35 random:220] CPU RNG state changed within GPU RNG context\n",
      "[NeMo W 2025-03-04 01:02:35 random:220] CPU RNG state changed within GPU RNG context\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "[NeMo W 2025-03-04 01:02:35 nemo_logging:405] Could not copy Trainer's 'max_steps' to LR scheduler's 'max_steps'. If you are not using an LR scheduler, this warning can safely be ignored.\n",
      "[NeMo I 2025-03-04 01:02:35 nemo_logging:393]  > number of parameters on (tensor, pipeline) model parallel rank (0 ,0): 1108204800\n",
      "[NeMo I 2025-03-04 01:02:35 utils:302] Setting up DistributedDataParallel with config DistributedDataParallelConfig(grad_reduce_in_fp32=False, overlap_grad_reduce=False, overlap_param_gather=False, align_param_gather=False, use_distributed_optimizer=False, num_distributed_optimizer_instances=1, check_for_nan_in_grad=True, check_for_large_grads=False, bucket_size=None, average_in_collective=False, fp8_param_gather=False)\n",
      "[NeMo I 2025-03-04 01:02:35 utils:323] Number of buckets for gradient all-reduce / reduce-scatter: 1\n",
      "    Params for bucket 1 (1108204800 elements):\n",
      "    \tmodule.decoder.layers.24.self_attention.linear_qkv.weight\n",
      "    \tmodule.decoder.layers.22.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.20.mixer.mixer.filter.gamma\n",
      "    \tmodule.decoder.layers.15.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.12.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.9.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.7.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.4.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.2.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.1.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.23.mixer.mixer.filter.R\n",
      "    \tmodule.decoder.layers.21.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.18.mixer.mixer.short_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.10.self_attention.linear_qkv.layer_norm_weight\n",
      "    \tmodule.decoder.layers.6.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.3.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.2.mixer.mixer.filter.gamma\n",
      "    \tmodule.decoder.layers.21.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.16.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.11.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.9.mixer.mixer.filter.gamma\n",
      "    \tmodule.decoder.layers.4.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.1.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.final_norm.weight\n",
      "    \tmodule.decoder.layers.23.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.20.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.13.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.12.mixer.mixer.filter.h\n",
      "    \tmodule.decoder.layers.10.self_attention.linear_proj.weight\n",
      "    \tmodule.decoder.layers.7.mixer.mixer.short_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.5.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.21.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.19.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.16.mixer.mixer.filter.p\n",
      "    \tmodule.decoder.layers.14.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.11.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.10.self_attention.linear_proj.bias\n",
      "    \tmodule.decoder.layers.6.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.3.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.0.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.21.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.15.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.13.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.4.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.2.mixer.mixer.filter.R\n",
      "    \tmodule.decoder.layers.1.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.23.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.20.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.16.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.13.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.8.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.5.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.3.self_attention.linear_qkv.layer_norm_weight\n",
      "    \tmodule.decoder.layers.24.self_attention.linear_proj.bias\n",
      "    \tmodule.decoder.layers.21.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.16.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.15.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.11.mixer.mixer.short_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.6.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.0.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.22.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.20.mixer.mixer.filter.p\n",
      "    \tmodule.decoder.layers.18.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.15.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.9.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.2.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.1.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.21.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.19.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.16.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.8.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.4.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.3.self_attention.linear_proj.bias\n",
      "    \tmodule.decoder.layers.0.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.24.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.20.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.17.self_attention.linear_qkv.weight\n",
      "    \tmodule.decoder.layers.15.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.12.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.9.mixer.mixer.filter.p\n",
      "    \tmodule.decoder.layers.7.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.5.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.2.mixer.mixer.filter.p\n",
      "    \tmodule.decoder.layers.23.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.20.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.19.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.16.mixer.mixer.filter.R\n",
      "    \tmodule.decoder.layers.14.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.13.mixer.mixer.filter.gamma\n",
      "    \tmodule.decoder.layers.5.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.2.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.24.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.22.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.19.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.18.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.14.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.9.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.6.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.4.mixer.mixer.short_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.0.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.22.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.20.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.16.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.13.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.12.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.9.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.8.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.5.mixer.mixer.filter.h\n",
      "    \tmodule.decoder.layers.2.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.2.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.23.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.21.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.19.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.14.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.11.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.8.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.6.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.2.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.24.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.22.mixer.mixer.filter.h\n",
      "    \tmodule.decoder.layers.20.mixer.mixer.filter.R\n",
      "    \tmodule.decoder.layers.18.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.14.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.9.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.2.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.18.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.16.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.13.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.10.self_attention.linear_qkv.weight\n",
      "    \tmodule.decoder.layers.8.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.6.mixer.mixer.filter.gamma\n",
      "    \tmodule.decoder.layers.0.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.24.self_attention.linear_qkv.layer_norm_weight\n",
      "    \tmodule.decoder.layers.22.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.20.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.14.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.12.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.9.mixer.mixer.filter.R\n",
      "    \tmodule.decoder.layers.7.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.1.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.23.mixer.mixer.filter.gamma\n",
      "    \tmodule.decoder.layers.18.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.15.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.13.mixer.mixer.filter.p\n",
      "    \tmodule.decoder.layers.12.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.7.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.1.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.embedding.word_embeddings.weight\n",
      "    \tmodule.decoder.layers.24.self_attention.linear_proj.weight\n",
      "    \tmodule.decoder.layers.21.mixer.mixer.short_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.14.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.9.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.4.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.0.mixer.mixer.short_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.20.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.17.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.13.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.12.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.7.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.5.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.1.mixer.mixer.filter.h\n",
      "    \tmodule.decoder.layers.23.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.18.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.16.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.13.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.11.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.8.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.3.self_attention.linear_qkv.weight\n",
      "    \tmodule.decoder.layers.2.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.0.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.22.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.19.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.17.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.15.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.11.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.9.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.6.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.18.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.15.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.13.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.12.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.12.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.7.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.1.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.23.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.17.self_attention.linear_proj.bias\n",
      "    \tmodule.decoder.layers.16.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.14.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.11.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.8.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.6.mixer.mixer.filter.p\n",
      "    \tmodule.decoder.layers.4.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.20.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.17.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.15.mixer.mixer.filter.h\n",
      "    \tmodule.decoder.layers.13.mixer.mixer.filter.R\n",
      "    \tmodule.decoder.layers.12.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.9.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.7.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.23.mixer.mixer.filter.p\n",
      "    \tmodule.decoder.layers.21.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.19.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.10.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.6.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.4.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.0.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.17.self_attention.linear_qkv.layer_norm_weight\n",
      "    \tmodule.decoder.layers.22.mixer.dense.bias\n",
      "    \tmodule.decoder.layers.19.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.15.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.11.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.6.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.5.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.5.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.1.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.23.mixer.hyena_proj_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.20.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.18.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.16.mixer.mixer.filter.gamma\n",
      "    \tmodule.decoder.layers.10.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.8.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.5.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.3.self_attention.linear_proj.weight\n",
      "    \tmodule.decoder.layers.1.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.23.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.22.mixer.dense_projection.layer_norm_weight\n",
      "    \tmodule.decoder.layers.19.mixer.mixer.filter.h\n",
      "    \tmodule.decoder.layers.17.self_attention.linear_proj.weight\n",
      "    \tmodule.decoder.layers.14.mixer.mixer.short_conv.short_conv_weight\n",
      "    \tmodule.decoder.layers.11.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.8.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.6.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.4.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.22.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.13.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.9.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.7.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.5.mixer.dense_projection.weight\n",
      "    \tmodule.decoder.layers.2.mixer.dense.weight\n",
      "    \tmodule.decoder.layers.23.mlp.linear_fc1.layer_norm_weight\n",
      "    \tmodule.decoder.layers.19.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.16.mixer.mixer.conv_bias\n",
      "    \tmodule.decoder.layers.10.mlp.linear_fc1.weight\n",
      "    \tmodule.decoder.layers.8.mixer.mixer.filter.h\n",
      "    \tmodule.decoder.layers.6.mixer.mixer.filter.R\n",
      "    \tmodule.decoder.layers.3.mlp.linear_fc2.weight\n",
      "    \tmodule.decoder.layers.0.mixer.dense.weight\n",
      "[NeMo I 2025-03-04 01:02:35 nemo_logging:393] Doing selective restore from RestoreConfig(path='nemo2_evo2_1b_8k', adapter_path=None, load_model_state=True, load_optim_state=False, load_artifacts=False)\n",
      "[NeMo I 2025-03-04 01:02:35 nemo_logging:393] Using <megatron.core.dist_checkpointing.strategies.fully_parallel.FullyParallelLoadStrategyWrapper object at 0x7bffabfab6e0> dist-ckpt load strategy.\n",
      "[WARNING  | py.warnings        ]: /workspaces/bionemo-framework/3rdparty/Megatron-LM/megatron/core/dist_checkpointing/strategies/torch.py:847: FutureWarning: `load_state_dict` is deprecated and will be removed in future versions. Please use `load` instead.\n",
      "  checkpoint.load_state_dict(\n",
      "\n",
      "[WARNING  | py.warnings        ]: /usr/local/lib/python3.12/dist-packages/torch/distributed/checkpoint/planner_helpers.py:316: FutureWarning: Please use DTensor instead and we are deprecating ShardedTensor.\n",
      "  device = getattr(value, \"device\", None)\n",
      "\n",
      "[NeMo I 2025-03-04 01:02:36 nemo_logging:393] Global Checkpoint Load : Rank : 0 : Start time : 1741050155.807s : Time spent in load_checkpoint: 0.618s\n",
      "[NeMo I 2025-03-04 01:02:36 nemo_logging:393] Restoring model weights from RestoreConfig(path='nemo2_evo2_1b_8k', adapter_path=None, load_model_state=True, load_optim_state=False, load_artifacts=False)\n",
      "[NeMo I 2025-03-04 01:02:36 nemo_logging:393] Finished restoring from RestoreConfig(path='nemo2_evo2_1b_8k', adapter_path=None, load_model_state=True, load_optim_state=False, load_artifacts=False), cleaning up.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Running command: {predict_var_command}\")\n",
    "!{predict_var_command}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We calculate the change in likelihoods for each variant relative to the likelihood of their respective wild-type sequence.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we load the prediction files and sequence id maps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find and load prediction files\n",
    "ref_pred_files = glob.glob(os.path.join(predict_ref_dir, \"predictions__rank_*.pt\"))\n",
    "var_pred_files = glob.glob(os.path.join(predict_var_dir, \"predictions__rank_*.pt\"))\n",
    "\n",
    "# Load sequence ID maps (maps sequence ID -> prediction index)\n",
    "with open(os.path.join(predict_ref_dir, \"seq_idx_map.json\"), \"r\") as f:\n",
    "    ref_seq_idx_map = json.load(f)\n",
    "with open(os.path.join(predict_var_dir, \"seq_idx_map.json\"), \"r\") as f:\n",
    "    var_seq_idx_map = json.load(f)\n",
    "\n",
    "# Load predictions\n",
    "ref_preds = torch.load(ref_pred_files[0])\n",
    "var_preds = torch.load(var_pred_files[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, calculate the delta score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chrom</th>\n",
       "      <th>pos</th>\n",
       "      <th>ref</th>\n",
       "      <th>alt</th>\n",
       "      <th>score</th>\n",
       "      <th>class</th>\n",
       "      <th>ref_fasta_name</th>\n",
       "      <th>var_fasta_name</th>\n",
       "      <th>ref_log_probs</th>\n",
       "      <th>var_log_probs</th>\n",
       "      <th>evo2_delta_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17</td>\n",
       "      <td>41199729</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>-2.646816</td>\n",
       "      <td>LOF</td>\n",
       "      <td>BRCA1_ref_pos_41199729_C_class_LOF</td>\n",
       "      <td>BRCA1_var_pos_41199729_CtoT_class_LOF</td>\n",
       "      <td>-0.952360</td>\n",
       "      <td>-0.953044</td>\n",
       "      <td>-0.000684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17</td>\n",
       "      <td>41215381</td>\n",
       "      <td>T</td>\n",
       "      <td>G</td>\n",
       "      <td>-2.352741</td>\n",
       "      <td>LOF</td>\n",
       "      <td>BRCA1_ref_pos_41215381_T_class_LOF</td>\n",
       "      <td>BRCA1_var_pos_41215381_TtoG_class_LOF</td>\n",
       "      <td>-0.848368</td>\n",
       "      <td>-0.848730</td>\n",
       "      <td>-0.000361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17</td>\n",
       "      <td>41215390</td>\n",
       "      <td>C</td>\n",
       "      <td>A</td>\n",
       "      <td>-1.371155</td>\n",
       "      <td>LOF</td>\n",
       "      <td>BRCA1_ref_pos_41215390_C_class_LOF</td>\n",
       "      <td>BRCA1_var_pos_41215390_CtoA_class_LOF</td>\n",
       "      <td>-0.848341</td>\n",
       "      <td>-0.847456</td>\n",
       "      <td>0.000885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17</td>\n",
       "      <td>41219688</td>\n",
       "      <td>T</td>\n",
       "      <td>A</td>\n",
       "      <td>-2.053136</td>\n",
       "      <td>LOF</td>\n",
       "      <td>BRCA1_ref_pos_41219688_T_class_LOF</td>\n",
       "      <td>BRCA1_var_pos_41219688_TtoA_class_LOF</td>\n",
       "      <td>-1.027623</td>\n",
       "      <td>-1.028068</td>\n",
       "      <td>-0.000445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>41219652</td>\n",
       "      <td>C</td>\n",
       "      <td>G</td>\n",
       "      <td>-2.026390</td>\n",
       "      <td>LOF</td>\n",
       "      <td>BRCA1_ref_pos_41219652_C_class_LOF</td>\n",
       "      <td>BRCA1_var_pos_41219652_CtoG_class_LOF</td>\n",
       "      <td>-1.032667</td>\n",
       "      <td>-1.032678</td>\n",
       "      <td>-0.000011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   chrom       pos ref alt     score class  \\\n",
       "0     17  41199729   C   T -2.646816   LOF   \n",
       "1     17  41215381   T   G -2.352741   LOF   \n",
       "2     17  41215390   C   A -1.371155   LOF   \n",
       "3     17  41219688   T   A -2.053136   LOF   \n",
       "4     17  41219652   C   G -2.026390   LOF   \n",
       "\n",
       "                       ref_fasta_name                         var_fasta_name  \\\n",
       "0  BRCA1_ref_pos_41199729_C_class_LOF  BRCA1_var_pos_41199729_CtoT_class_LOF   \n",
       "1  BRCA1_ref_pos_41215381_T_class_LOF  BRCA1_var_pos_41215381_TtoG_class_LOF   \n",
       "2  BRCA1_ref_pos_41215390_C_class_LOF  BRCA1_var_pos_41215390_CtoA_class_LOF   \n",
       "3  BRCA1_ref_pos_41219688_T_class_LOF  BRCA1_var_pos_41219688_TtoA_class_LOF   \n",
       "4  BRCA1_ref_pos_41219652_C_class_LOF  BRCA1_var_pos_41219652_CtoG_class_LOF   \n",
       "\n",
       "   ref_log_probs  var_log_probs  evo2_delta_score  \n",
       "0      -0.952360      -0.953044         -0.000684  \n",
       "1      -0.848368      -0.848730         -0.000361  \n",
       "2      -0.848341      -0.847456          0.000885  \n",
       "3      -1.027623      -1.028068         -0.000445  \n",
       "4      -1.032667      -1.032678         -0.000011  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# next, calculate change in likelihoods\n",
    "ref_log_probs = []\n",
    "var_log_probs = []\n",
    "for _, row in brca1_df.iterrows():\n",
    "    ref_name = row['ref_fasta_name']\n",
    "    var_name = row['var_fasta_name']\n",
    "    ref_log_probs.append(ref_preds['log_probs_seqs'][ref_seq_idx_map[ref_name]].item())\n",
    "    var_log_probs.append(var_preds['log_probs_seqs'][var_seq_idx_map[var_name]].item())\n",
    "brca1_df['ref_log_probs'] = ref_log_probs\n",
    "brca1_df['var_log_probs'] = var_log_probs\n",
    "# ideally probability of a broken variant is lower than a good one. So a bad var - good ref is negative.\n",
    "brca1_df['evo2_delta_score'] = brca1_df['var_log_probs'] - brca1_df['ref_log_probs']\n",
    "brca1_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This delta likelihood should be predictive of how disruptive the SNV is to the protein's function: the lower the delta, the more likely that the SNV is disruptive. We can show this by comparing the distributions of delta likelihoods for the two classes of SNVs (functional/intermediate vs loss-of-function)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(4, 2))\n",
    "\n",
    "# Plot stripplot of distributions\n",
    "p = sns.stripplot(\n",
    "    data=brca1_df,\n",
    "    x='evo2_delta_score',\n",
    "    y='class',\n",
    "    hue='class',\n",
    "    order=['FUNC/INT', 'LOF'],\n",
    "    palette=['#777777', 'C3'],\n",
    "    size=2,\n",
    "    jitter=0.3,\n",
    ")\n",
    "\n",
    "# Mark medians from each distribution\n",
    "sns.boxplot(showmeans=True,\n",
    "            meanline=True,\n",
    "            meanprops={'visible': False},\n",
    "            medianprops={'color': 'k', 'ls': '-', 'lw': 2},\n",
    "            whiskerprops={'visible': False},\n",
    "            zorder=10,\n",
    "            x=\"evo2_delta_score\",\n",
    "            y=\"class\",\n",
    "            data=brca1_df,\n",
    "            showfliers=False,\n",
    "            showbox=False,\n",
    "            showcaps=False,\n",
    "            ax=p)\n",
    "plt.xlabel('Delta likelihood score, Evo 2')\n",
    "plt.ylabel('BRCA1 SNV class')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also calculate the area under the receiver operating characteristic curve (AUROC) of this zero-shot prediction method. Note that the results are nearly random unless you are on one of the following configurations:\n",
    "* `--fp8` on an fp8 enabled GPU with either the 1b or 7b models. The 40b likely works as well.\n",
    "* the 7b model uniquely seems to work well without `--fp8` so if you are on an older device, the 7b model should produce\n",
    "  robust results. Change the `MODEL_SIZE` earlier in this tutorial and rerun for good results in that case.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero-shot prediction AUROC: 0.77\n"
     ]
    }
   ],
   "source": [
    "# Calculate AUROC of zero-shot predictions\n",
    "#  class 1 is LOF which is the bad thing. That means we expect this to be more negative.\n",
    "y_true = (brca1_df['class'] == 'LOF')\n",
    "auroc = roc_auc_score(y_true, -brca1_df['evo2_delta_score'])\n",
    "print(f'Zero-shot prediction AUROC: {auroc:.2}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
